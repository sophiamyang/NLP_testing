{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get test data from checklist test\n",
    "\n",
    "As shown in the end of the SQuAD-create-test-suite.ipynb, we can get all examples from the test suite. However, I'm not sure how to get the correct answers, especially for the invariance test cases. So I'm going to process and save all the test examples in csv files and read in later. \n",
    "\n",
    "\n",
    "This file is copied from SQuAD-create-test-suite.ipynb. I removed the irrelavant cells. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
    "    AutoModelForQuestionAnswering, Trainer, TrainingArguments, HfArgumentParser\n",
    "from transformers import pipeline \n",
    "\n",
    "model_name = \"trained_model_squad1/\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = pipeline('question-answering', model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import checklist\n",
    "import spacy\n",
    "import itertools\n",
    "\n",
    "import checklist.editor\n",
    "import checklist.text_generation\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "from checklist.test_suite import TestSuite\n",
    "import numpy as np\n",
    "import spacy\n",
    "from checklist.perturb import Perturb\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/syang/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127c0241d9e5455db512953f69ebe14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87599 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f43b39167a4f0c91d1a3e26b66f47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{\"text\": [\"Saint Bernadette Soubirous\"], \"answ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "\n",
       "                                             answers  \n",
       "0  {\"text\": [\"Saint Bernadette Soubirous\"], \"answ...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAVE SQUAD DATASET TO CSV \n",
    "\n",
    "dataset = datasets.load_dataset('squad')\n",
    "# def format_dataset(example):\n",
    "#     \"\"\"\n",
    "#     format answers from dict to json\n",
    "#     so that data looks consistent when exporting to csv\n",
    "#     \"\"\"\n",
    "    example['answers'] = json.dumps(example['answers'])\n",
    "#     return example\n",
    "\n",
    "# dataset = dataset.map(format_dataset)\n",
    "# dataset['train'].to_csv('train.csv', index=None)\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def dataset_fmt(t, file_name):\n",
    "    \"\"\"\n",
    "    format t to acceptable dataframe format \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([\n",
    "        {'context':i[k][0], 'question':i[k][1], 'answers_text': j[k]}\n",
    "        for i, j in zip(t.data, t.labels)\n",
    "        for k in range(len(i))\n",
    "    ])\n",
    "    df['answer_start'] = df.apply(lambda row: row['context'].index(row['answers_text']), axis=1)\n",
    "    df['answers'] = df.apply(lambda row: {'text': [row['answers_text']], 'answer_start': [row['answer_start']]}, axis=1)\n",
    "    df = df.drop(columns=['answers_text', 'answer_start'])\n",
    "    df['answers'] = df['answers'].apply(json.dumps)\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    df.to_csv(f'new_data/{file_name}.csv', index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def inv_dataset_fmt(t, file_name, df_train=df_train):\n",
    "    \"\"\"\n",
    "    use original answers for invariance cases\n",
    "    note that in many cases start position changes, that's why we find the correct index \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([{'context':i[0][0], 'question':i[0][1], 'context_modified':i[1][0], 'question_modified':i[1][1]} for i in t.data])\n",
    "    df = (\n",
    "        df\n",
    "        .merge(df_train, on=['context','question'], how='inner')\n",
    "        .drop(columns=['context', 'question', 'id', 'title'])\n",
    "        .rename(columns={'context_modified': 'context', 'question_modified':'question'})\n",
    "        .drop_duplicates(subset=['context','question'])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    df = find_matching_index(df)\n",
    "    df['answers'] = df['answers'].apply(json.dumps)\n",
    "    df.to_csv(f'new_data/{file_name}.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_matching(string, sentence):\n",
    "    matching_lst = []\n",
    "    for m in re.finditer(re.escape(string), sentence): #re.escape deals with weird character issues\n",
    "        matching_lst.append(m.start())\n",
    "    return matching_lst\n",
    "\n",
    "def find_matching_index(df):\n",
    "    for index, row in df.iterrows(): \n",
    "        row['answers'] = json.loads(row['answers'])\n",
    "        for i in range(len(row['answers']['text'])):\n",
    "            original_index = row['answers']['answer_start'][i]\n",
    "            all_matched_indexes = find_all_matching(row['answers']['text'][i], row['context'])\n",
    "            if len(all_matched_indexes) ==0:\n",
    "                pass\n",
    "            elif original_index in all_matched_indexes:\n",
    "                # if the original index is in the matched indexes, do nothing\n",
    "                pass\n",
    "            else:\n",
    "                print(index)\n",
    "                print(row)\n",
    "                print('changed')\n",
    "                # if not, choose the index that's the closest to the original index\n",
    "                row['answers']['answer_start'][i] = min(all_matched_indexes, key=lambda x: abs(x - original_index))\n",
    "                print(original_index)\n",
    "                print(row['answers']['answer_start'][i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<checklist.text_generation.TextGenerator at 0x7f2164f52d00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor = checklist.editor.Editor()\n",
    "editor.tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syang/miniconda3/envs/nlp/lib/python3.9/site-packages/checklist/text_generation.py:171: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  to_pred = torch.tensor(to_pred, device=self.device).to(torch.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smarter, better, older, younger, taller, worse, different, stronger, cooler, nicer, tougher, shorter, bigger, hotter, more, darker, happier, smaller, faster, richer, wiser, thinner, less, weaker, larger, quieter, cleaner, closer, healthier, heavier, colder, slower, harder, wealthier, safer, quicker, longer, higher, cheaper, thicker, louder, sharper, lighter, warmer, brighter, greater, deeper, lower, easier, softer, smoother, poorer, other, stranger, newer, stricter, simpler, clearer, superior, tighter\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(editor.suggest('{first_name} is {mask} than {first_name2}.')[:60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = ['old', 'smart', 'tall', 'young', 'strong', 'short', 'tough', 'cool', 'fast', 'nice', 'small', 'dark', 'wise', 'rich', 'great', 'weak', 'high', 'slow', 'strange', 'clean']\n",
    "adj = [(x.rstrip('e'), x) for x in adj]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tall', 'tall')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template(\n",
    "    [(\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is {adj[0]}er?'\n",
    "    )\n",
    "    ],\n",
    "    labels = ['{first_name}'],\n",
    "    adj=adj,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    )\n",
    "name = 'A is COMP than B. Who is more COMP?'\n",
    "# description = ''\n",
    "# test = MFT(**t, name=name, description=description, capability='Vocabulary')\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jim is cleaner than Amanda.</td>\n",
       "      <td>Who is cleaner?</td>\n",
       "      <td>{\"text\": [\"Jim\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony is richer than Lucy.</td>\n",
       "      <td>Who is richer?</td>\n",
       "      <td>{\"text\": [\"Anthony\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald is smarter than Patricia.</td>\n",
       "      <td>Who is smarter?</td>\n",
       "      <td>{\"text\": [\"Donald\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Francis is stronger than Jessica.</td>\n",
       "      <td>Who is stronger?</td>\n",
       "      <td>{\"text\": [\"Francis\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eleanor is cooler than Bob.</td>\n",
       "      <td>Who is cooler?</td>\n",
       "      <td>{\"text\": [\"Eleanor\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Arthur is cleaner than Bobby.</td>\n",
       "      <td>Who is cleaner?</td>\n",
       "      <td>{\"text\": [\"Arthur\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Joseph is wiser than Michael.</td>\n",
       "      <td>Who is wiser?</td>\n",
       "      <td>{\"text\": [\"Joseph\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Dick is stronger than Grace.</td>\n",
       "      <td>Who is stronger?</td>\n",
       "      <td>{\"text\": [\"Dick\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Caroline is richer than Claire.</td>\n",
       "      <td>Who is richer?</td>\n",
       "      <td>{\"text\": [\"Caroline\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Anna is faster than Kenneth.</td>\n",
       "      <td>Who is faster?</td>\n",
       "      <td>{\"text\": [\"Anna\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               context          question  \\\n",
       "0          Jim is cleaner than Amanda.   Who is cleaner?   \n",
       "1         Anthony is richer than Lucy.    Who is richer?   \n",
       "2     Donald is smarter than Patricia.   Who is smarter?   \n",
       "3    Francis is stronger than Jessica.  Who is stronger?   \n",
       "4          Eleanor is cooler than Bob.    Who is cooler?   \n",
       "..                                 ...               ...   \n",
       "493      Arthur is cleaner than Bobby.   Who is cleaner?   \n",
       "494      Joseph is wiser than Michael.     Who is wiser?   \n",
       "495       Dick is stronger than Grace.  Who is stronger?   \n",
       "496    Caroline is richer than Claire.    Who is richer?   \n",
       "497       Anna is faster than Kenneth.    Who is faster?   \n",
       "\n",
       "                                         answers  \n",
       "0         {\"text\": [\"Jim\"], \"answer_start\": [0]}  \n",
       "1     {\"text\": [\"Anthony\"], \"answer_start\": [0]}  \n",
       "2      {\"text\": [\"Donald\"], \"answer_start\": [0]}  \n",
       "3     {\"text\": [\"Francis\"], \"answer_start\": [0]}  \n",
       "4     {\"text\": [\"Eleanor\"], \"answer_start\": [0]}  \n",
       "..                                           ...  \n",
       "493    {\"text\": [\"Arthur\"], \"answer_start\": [0]}  \n",
       "494    {\"text\": [\"Joseph\"], \"answer_start\": [0]}  \n",
       "495      {\"text\": [\"Dick\"], \"answer_start\": [0]}  \n",
       "496  {\"text\": [\"Caroline\"], \"answer_start\": [0]}  \n",
       "497      {\"text\": [\"Anna\"], \"answer_start\": [0]}  \n",
       "\n",
       "[498 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"compare_more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template(\n",
    "    [(\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is less {adj[1]}?'\n",
    "    )\n",
    "    ],\n",
    "    labels = ['{first_name1}'],\n",
    "    adj=adj,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    )\n",
    "name = 'A is COMP than B. Who is less COMP?'\n",
    "# description = ''\n",
    "# test = MFT(**t, name=name, description=description, capability='Vocabulary')\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George is older than Joseph.</td>\n",
       "      <td>Who is less old?</td>\n",
       "      <td>{\"text\": [\"Joseph\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evelyn is smaller than Frances.</td>\n",
       "      <td>Who is less small?</td>\n",
       "      <td>{\"text\": [\"Frances\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donna is wiser than Ashley.</td>\n",
       "      <td>Who is less wise?</td>\n",
       "      <td>{\"text\": [\"Ashley\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caroline is shorter than Larry.</td>\n",
       "      <td>Who is less short?</td>\n",
       "      <td>{\"text\": [\"Larry\"], \"answer_start\": [25]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jimmy is darker than Thomas.</td>\n",
       "      <td>Who is less dark?</td>\n",
       "      <td>{\"text\": [\"Thomas\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Charles is greater than Sam.</td>\n",
       "      <td>Who is less great?</td>\n",
       "      <td>{\"text\": [\"Sam\"], \"answer_start\": [24]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Julia is higher than Francis.</td>\n",
       "      <td>Who is less high?</td>\n",
       "      <td>{\"text\": [\"Francis\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Nicole is weaker than Matthew.</td>\n",
       "      <td>Who is less weak?</td>\n",
       "      <td>{\"text\": [\"Matthew\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Kevin is cleaner than Don.</td>\n",
       "      <td>Who is less clean?</td>\n",
       "      <td>{\"text\": [\"Don\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Samuel is stronger than Victoria.</td>\n",
       "      <td>Who is less strong?</td>\n",
       "      <td>{\"text\": [\"Victoria\"], \"answer_start\": [24]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               context             question  \\\n",
       "0         George is older than Joseph.     Who is less old?   \n",
       "1      Evelyn is smaller than Frances.   Who is less small?   \n",
       "2          Donna is wiser than Ashley.    Who is less wise?   \n",
       "3      Caroline is shorter than Larry.   Who is less short?   \n",
       "4         Jimmy is darker than Thomas.    Who is less dark?   \n",
       "..                                 ...                  ...   \n",
       "489       Charles is greater than Sam.   Who is less great?   \n",
       "490      Julia is higher than Francis.    Who is less high?   \n",
       "491     Nicole is weaker than Matthew.    Who is less weak?   \n",
       "492         Kevin is cleaner than Don.   Who is less clean?   \n",
       "493  Samuel is stronger than Victoria.  Who is less strong?   \n",
       "\n",
       "                                          answers  \n",
       "0      {\"text\": [\"Joseph\"], \"answer_start\": [21]}  \n",
       "1     {\"text\": [\"Frances\"], \"answer_start\": [23]}  \n",
       "2      {\"text\": [\"Ashley\"], \"answer_start\": [20]}  \n",
       "3       {\"text\": [\"Larry\"], \"answer_start\": [25]}  \n",
       "4      {\"text\": [\"Thomas\"], \"answer_start\": [21]}  \n",
       "..                                            ...  \n",
       "489       {\"text\": [\"Sam\"], \"answer_start\": [24]}  \n",
       "490   {\"text\": [\"Francis\"], \"answer_start\": [21]}  \n",
       "491   {\"text\": [\"Matthew\"], \"answer_start\": [22]}  \n",
       "492       {\"text\": [\"Don\"], \"answer_start\": [22]}  \n",
       "493  {\"text\": [\"Victoria\"], \"answer_start\": [24]}  \n",
       "\n",
       "[494 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"compare_less\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossproduct(t):\n",
    "    # takes the output of editor.template and does the cross product of contexts and qas\n",
    "    ret = []\n",
    "    ret_labels = []\n",
    "    for x in t.data:\n",
    "        cs = x['contexts']\n",
    "        qas = x['qas']\n",
    "        d = list(itertools.product(cs, qas))\n",
    "        ret.append([(x[0], x[1][0]) for x in d])\n",
    "        ret_labels.append([x[1][1] for x in d])\n",
    "    t.data = ret\n",
    "    t.labels = ret_labels\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very, pretty, extremely, also, still, quite, more, really, not, clearly, fairly, incredibly, particularly, now, understandably, rather, cautiously, surprisingly, certainly, feeling, so, especially, definitely, generally, most, highly, super, reportedly, being, obviously\n"
     ]
    }
   ],
   "source": [
    "state = editor.suggest('John is very {mask} about the project.')[:20]\n",
    "print(', '.join(editor.suggest('John is {mask} {state} about the project.', state=state)[:30]))\n",
    "very = ['very', 'extremely', 'really', 'quite', 'incredibly', 'particularly', 'highly', 'super']\n",
    "somewhat = ['a little', 'somewhat', 'slightly', 'mildly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {s} about the project.',\n",
    "            '{first_name1} is {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "            '{first_name} is {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {s} about the project.',\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is most {s} about the project?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is least {s} about the project?',\n",
    "                '{first_name1}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s = state,\n",
    "    very=very,\n",
    "    somewhat=somewhat,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'Intensifiers (very, super, extremely) and reducers (somewhat, kinda, etc)?'\n",
    "# desc = ''\n",
    "# test = MFT(**t, name=name, description=desc, capability='Vocabulary')\n",
    "# suite.add(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ken is incredibly curious about the project. D...</td>\n",
       "      <td>Who is most curious about the project?</td>\n",
       "      <td>{\"text\": [\"Ken\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ken is incredibly curious about the project. D...</td>\n",
       "      <td>Who is least curious about the project?</td>\n",
       "      <td>{\"text\": [\"Diana\"], \"answer_start\": [45]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diana is curious about the project. Ken is inc...</td>\n",
       "      <td>Who is most curious about the project?</td>\n",
       "      <td>{\"text\": [\"Ken\"], \"answer_start\": [36]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana is curious about the project. Ken is inc...</td>\n",
       "      <td>Who is least curious about the project?</td>\n",
       "      <td>{\"text\": [\"Diana\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ken is curious about the project. Diana is sli...</td>\n",
       "      <td>Who is most curious about the project?</td>\n",
       "      <td>{\"text\": [\"Ken\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5959</th>\n",
       "      <td>Pamela is mildly hopeful about the project. Ad...</td>\n",
       "      <td>Who is least hopeful about the project?</td>\n",
       "      <td>{\"text\": [\"Pamela\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5960</th>\n",
       "      <td>Adam is super hopeful about the project. Pamel...</td>\n",
       "      <td>Who is most hopeful about the project?</td>\n",
       "      <td>{\"text\": [\"Adam\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5961</th>\n",
       "      <td>Adam is super hopeful about the project. Pamel...</td>\n",
       "      <td>Who is least hopeful about the project?</td>\n",
       "      <td>{\"text\": [\"Pamela\"], \"answer_start\": [41]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5962</th>\n",
       "      <td>Pamela is mildly hopeful about the project. Ad...</td>\n",
       "      <td>Who is most hopeful about the project?</td>\n",
       "      <td>{\"text\": [\"Adam\"], \"answer_start\": [44]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>Pamela is mildly hopeful about the project. Ad...</td>\n",
       "      <td>Who is least hopeful about the project?</td>\n",
       "      <td>{\"text\": [\"Pamela\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5964 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0     Ken is incredibly curious about the project. D...   \n",
       "1     Ken is incredibly curious about the project. D...   \n",
       "2     Diana is curious about the project. Ken is inc...   \n",
       "3     Diana is curious about the project. Ken is inc...   \n",
       "4     Ken is curious about the project. Diana is sli...   \n",
       "...                                                 ...   \n",
       "5959  Pamela is mildly hopeful about the project. Ad...   \n",
       "5960  Adam is super hopeful about the project. Pamel...   \n",
       "5961  Adam is super hopeful about the project. Pamel...   \n",
       "5962  Pamela is mildly hopeful about the project. Ad...   \n",
       "5963  Pamela is mildly hopeful about the project. Ad...   \n",
       "\n",
       "                                     question  \\\n",
       "0      Who is most curious about the project?   \n",
       "1     Who is least curious about the project?   \n",
       "2      Who is most curious about the project?   \n",
       "3     Who is least curious about the project?   \n",
       "4      Who is most curious about the project?   \n",
       "...                                       ...   \n",
       "5959  Who is least hopeful about the project?   \n",
       "5960   Who is most hopeful about the project?   \n",
       "5961  Who is least hopeful about the project?   \n",
       "5962   Who is most hopeful about the project?   \n",
       "5963  Who is least hopeful about the project?   \n",
       "\n",
       "                                         answers  \n",
       "0         {\"text\": [\"Ken\"], \"answer_start\": [0]}  \n",
       "1      {\"text\": [\"Diana\"], \"answer_start\": [45]}  \n",
       "2        {\"text\": [\"Ken\"], \"answer_start\": [36]}  \n",
       "3       {\"text\": [\"Diana\"], \"answer_start\": [0]}  \n",
       "4         {\"text\": [\"Ken\"], \"answer_start\": [0]}  \n",
       "...                                          ...  \n",
       "5959   {\"text\": [\"Pamela\"], \"answer_start\": [0]}  \n",
       "5960     {\"text\": [\"Adam\"], \"answer_start\": [0]}  \n",
       "5961  {\"text\": [\"Pamela\"], \"answer_start\": [41]}  \n",
       "5962    {\"text\": [\"Adam\"], \"answer_start\": [44]}  \n",
       "5963   {\"text\": [\"Pamela\"], \"answer_start\": [0]}  \n",
       "\n",
       "[5964 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"intensifiers_reducers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size, chape, color, age, material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import munch\n",
    "order = ['size', 'shape', 'age', 'color']\n",
    "props = []\n",
    "properties = {\n",
    "    'color' : ['red', 'blue','yellow', 'green', 'pink', 'white', 'black', 'orange', 'grey', 'purple', 'brown'],\n",
    "    'size' : ['big', 'small', 'tiny', 'enormous'],\n",
    "    'age' : ['old', 'new'],\n",
    "    'shape' : ['round', 'oval', 'square', 'triangular'],\n",
    "    'material' : ['iron', 'wooden', 'ceramic', 'glass', 'stone']\n",
    "}\n",
    "for i in range(len(order)):\n",
    "    for j in range(i + 1, len(order)):\n",
    "        p1, p2 = order[i], order[j]\n",
    "        for v1, v2 in itertools.product(properties[p1], properties[p2]):\n",
    "            props.append(munch.Munch({\n",
    "                'p1': p1,\n",
    "                'p2': p2,\n",
    "                'v1': v1,\n",
    "                'v2': v2,\n",
    "            }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sofa, couch, wall, carpet, chair, table, light, lamp, door, clock, mirror, desk, bed, TV, bar, television, window, box, tree, painting, curtain, fan, fridge, screen, wallpaper, piano, rug, shelf, camera, candle\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(editor.suggest('There is {a:p.v1} {p.v2} {mask} in the room.', p=props, verbose=False)[:30]))\n",
    "objects = ['box', 'clock', 'table', 'object', 'toy', 'painting', 'sculpture', 'thing', 'figure']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'There is {a:p.v1} {p.v2} {obj} in the room.',\n",
    "            'There is {a:obj} in the room. The {obj} is {p.v1} and {p.v2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What {p.p1} is the {obj}?',\n",
    "                '{p.v1}'\n",
    "            ), \n",
    "            (\n",
    "                'What {p.p2} is the {obj}?',\n",
    "                '{p.v2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    obj=objects,\n",
    "    p=props,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'size, shape, age, color'\n",
    "desc = ''\n",
    "# test = MFT(**t, name=name, description=desc, capability='Taxonomy')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is an oval brown table in the room.</td>\n",
       "      <td>What shape is the table?</td>\n",
       "      <td>{\"text\": [\"oval\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is an oval brown table in the room.</td>\n",
       "      <td>What color is the table?</td>\n",
       "      <td>{\"text\": [\"brown\"], \"answer_start\": [17]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There is a table in the room. The table is ova...</td>\n",
       "      <td>What shape is the table?</td>\n",
       "      <td>{\"text\": [\"oval\"], \"answer_start\": [43]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There is a table in the room. The table is ova...</td>\n",
       "      <td>What color is the table?</td>\n",
       "      <td>{\"text\": [\"brown\"], \"answer_start\": [52]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is a big oval toy in the room.</td>\n",
       "      <td>What size is the toy?</td>\n",
       "      <td>{\"text\": [\"big\"], \"answer_start\": [11]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>There is a box in the room. The box is enormou...</td>\n",
       "      <td>What color is the box?</td>\n",
       "      <td>{\"text\": [\"blue\"], \"answer_start\": [52]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>There is an enormous black thing in the room.</td>\n",
       "      <td>What size is the thing?</td>\n",
       "      <td>{\"text\": [\"enormous\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>There is an enormous black thing in the room.</td>\n",
       "      <td>What color is the thing?</td>\n",
       "      <td>{\"text\": [\"black\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>There is a thing in the room. The thing is eno...</td>\n",
       "      <td>What size is the thing?</td>\n",
       "      <td>{\"text\": [\"enormous\"], \"answer_start\": [43]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>There is a thing in the room. The thing is eno...</td>\n",
       "      <td>What color is the thing?</td>\n",
       "      <td>{\"text\": [\"black\"], \"answer_start\": [56]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1640 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0             There is an oval brown table in the room.   \n",
       "1             There is an oval brown table in the room.   \n",
       "2     There is a table in the room. The table is ova...   \n",
       "3     There is a table in the room. The table is ova...   \n",
       "4                  There is a big oval toy in the room.   \n",
       "...                                                 ...   \n",
       "1635  There is a box in the room. The box is enormou...   \n",
       "1636      There is an enormous black thing in the room.   \n",
       "1637      There is an enormous black thing in the room.   \n",
       "1638  There is a thing in the room. The thing is eno...   \n",
       "1639  There is a thing in the room. The thing is eno...   \n",
       "\n",
       "                      question                                       answers  \n",
       "0     What shape is the table?      {\"text\": [\"oval\"], \"answer_start\": [12]}  \n",
       "1     What color is the table?     {\"text\": [\"brown\"], \"answer_start\": [17]}  \n",
       "2     What shape is the table?      {\"text\": [\"oval\"], \"answer_start\": [43]}  \n",
       "3     What color is the table?     {\"text\": [\"brown\"], \"answer_start\": [52]}  \n",
       "4        What size is the toy?       {\"text\": [\"big\"], \"answer_start\": [11]}  \n",
       "...                        ...                                           ...  \n",
       "1635    What color is the box?      {\"text\": [\"blue\"], \"answer_start\": [52]}  \n",
       "1636   What size is the thing?  {\"text\": [\"enormous\"], \"answer_start\": [12]}  \n",
       "1637  What color is the thing?     {\"text\": [\"black\"], \"answer_start\": [21]}  \n",
       "1638   What size is the thing?  {\"text\": [\"enormous\"], \"answer_start\": [43]}  \n",
       "1639  What color is the thing?     {\"text\": [\"black\"], \"answer_start\": [56]}  \n",
       "\n",
       "[1640 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"size_shape_age_color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professions vs nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "professions = editor.suggest('{first_name} works as {a:mask}.')[:30]\n",
    "professions += editor.suggest('{first_name} {last_name} works as {a:mask}.')[:30]\n",
    "professions = list(set(professions))\n",
    "if 'translator' in professions:\n",
    "    professions.remove('translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    return string.lstrip('[a,the,an,in,at] ').rstrip('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expect_squad(x, pred, conf, label=None, meta=None):\n",
    "    return clean(pred) == clean(label)\n",
    "expect_squad = Expect.single(expect_squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:nat} {prof}.',\n",
    "            '{first_name} is {a:prof}. {first_name} is {nat}.',\n",
    "            '{first_name} is {nat}. {first_name} is {a:prof}.',\n",
    "            '{first_name} is {nat} and {a:prof}.',\n",
    "            '{first_name} is {a:prof} and {nat}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What is {first_name}\\'s job?',\n",
    "                '{prof}'\n",
    "            ), \n",
    "            (\n",
    "                'What is {first_name}\\'s nationality?',\n",
    "                '{nat}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    nat = editor.lexicons['nationality'][:10],\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True,\n",
    "    ))\n",
    "name = 'Profession vs nationality'\n",
    "# test = MFT(**t, name=name, expect=expect_squad, description='',  capability='Taxonomy')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daniel is a Chinese reporter.</td>\n",
       "      <td>What is Daniel's job?</td>\n",
       "      <td>{\"text\": [\"reporter\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daniel is a Chinese reporter.</td>\n",
       "      <td>What is Daniel's nationality?</td>\n",
       "      <td>{\"text\": [\"Chinese\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daniel is a reporter. Daniel is Chinese.</td>\n",
       "      <td>What is Daniel's job?</td>\n",
       "      <td>{\"text\": [\"reporter\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daniel is a reporter. Daniel is Chinese.</td>\n",
       "      <td>What is Daniel's nationality?</td>\n",
       "      <td>{\"text\": [\"Chinese\"], \"answer_start\": [32]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daniel is Chinese. Daniel is a reporter.</td>\n",
       "      <td>What is Daniel's job?</td>\n",
       "      <td>{\"text\": [\"reporter\"], \"answer_start\": [31]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>Katherine is Nigerian. Katherine is a producer.</td>\n",
       "      <td>What is Katherine's nationality?</td>\n",
       "      <td>{\"text\": [\"Nigerian\"], \"answer_start\": [13]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>Katherine is Nigerian and a producer.</td>\n",
       "      <td>What is Katherine's job?</td>\n",
       "      <td>{\"text\": [\"producer\"], \"answer_start\": [28]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>Katherine is Nigerian and a producer.</td>\n",
       "      <td>What is Katherine's nationality?</td>\n",
       "      <td>{\"text\": [\"Nigerian\"], \"answer_start\": [13]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>Katherine is a producer and Nigerian.</td>\n",
       "      <td>What is Katherine's job?</td>\n",
       "      <td>{\"text\": [\"producer\"], \"answer_start\": [15]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>Katherine is a producer and Nigerian.</td>\n",
       "      <td>What is Katherine's nationality?</td>\n",
       "      <td>{\"text\": [\"Nigerian\"], \"answer_start\": [28]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4990 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context  \\\n",
       "0                       Daniel is a Chinese reporter.   \n",
       "1                       Daniel is a Chinese reporter.   \n",
       "2            Daniel is a reporter. Daniel is Chinese.   \n",
       "3            Daniel is a reporter. Daniel is Chinese.   \n",
       "4            Daniel is Chinese. Daniel is a reporter.   \n",
       "...                                               ...   \n",
       "4985  Katherine is Nigerian. Katherine is a producer.   \n",
       "4986            Katherine is Nigerian and a producer.   \n",
       "4987            Katherine is Nigerian and a producer.   \n",
       "4988            Katherine is a producer and Nigerian.   \n",
       "4989            Katherine is a producer and Nigerian.   \n",
       "\n",
       "                              question  \\\n",
       "0                What is Daniel's job?   \n",
       "1        What is Daniel's nationality?   \n",
       "2                What is Daniel's job?   \n",
       "3        What is Daniel's nationality?   \n",
       "4                What is Daniel's job?   \n",
       "...                                ...   \n",
       "4985  What is Katherine's nationality?   \n",
       "4986          What is Katherine's job?   \n",
       "4987  What is Katherine's nationality?   \n",
       "4988          What is Katherine's job?   \n",
       "4989  What is Katherine's nationality?   \n",
       "\n",
       "                                           answers  \n",
       "0     {\"text\": [\"reporter\"], \"answer_start\": [20]}  \n",
       "1      {\"text\": [\"Chinese\"], \"answer_start\": [12]}  \n",
       "2     {\"text\": [\"reporter\"], \"answer_start\": [12]}  \n",
       "3      {\"text\": [\"Chinese\"], \"answer_start\": [32]}  \n",
       "4     {\"text\": [\"reporter\"], \"answer_start\": [31]}  \n",
       "...                                            ...  \n",
       "4985  {\"text\": [\"Nigerian\"], \"answer_start\": [13]}  \n",
       "4986  {\"text\": [\"producer\"], \"answer_start\": [28]}  \n",
       "4987  {\"text\": [\"Nigerian\"], \"answer_start\": [13]}  \n",
       "4988  {\"text\": [\"producer\"], \"answer_start\": [15]}  \n",
       "4989  {\"text\": [\"Nigerian\"], \"answer_start\": [28]}  \n",
       "\n",
       "[4990 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"profession_nationality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal vs vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['dog', 'cat', 'bull', 'cow', 'fish', 'serpent', 'snake', 'lizard', 'hamster', 'rabbit', 'guinea pig', 'iguana', 'duck']\n",
    "vehicles = ['car', 'truck', 'train', 'motorcycle', 'bike', 'firetruck', 'tractor', 'van', 'SUV', 'minivan']\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} has {a:animal} and {a:vehicle}.',\n",
    "            '{first_name} has {a:vehicle} and {a:animal}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What animal does {first_name} have?',\n",
    "                '{animal}'\n",
    "            ), \n",
    "            (\n",
    "                'What vehicle does {first_name} have?',\n",
    "                '{vehicle}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    animal=animals,\n",
    "    vehicle=vehicles,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'Animal vs Vehicle'\n",
    "# test = MFT(**t, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice has a lizard and a minivan.</td>\n",
       "      <td>What animal does Alice have?</td>\n",
       "      <td>{\"text\": [\"lizard\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice has a lizard and a minivan.</td>\n",
       "      <td>What vehicle does Alice have?</td>\n",
       "      <td>{\"text\": [\"minivan\"], \"answer_start\": [25]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice has a minivan and a lizard.</td>\n",
       "      <td>What animal does Alice have?</td>\n",
       "      <td>{\"text\": [\"lizard\"], \"answer_start\": [26]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice has a minivan and a lizard.</td>\n",
       "      <td>What vehicle does Alice have?</td>\n",
       "      <td>{\"text\": [\"minivan\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michelle has a bull and a van.</td>\n",
       "      <td>What animal does Michelle have?</td>\n",
       "      <td>{\"text\": [\"bull\"], \"answer_start\": [15]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>Elaine has a tractor and an iguana.</td>\n",
       "      <td>What vehicle does Elaine have?</td>\n",
       "      <td>{\"text\": [\"tractor\"], \"answer_start\": [13]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>Linda has a fish and a truck.</td>\n",
       "      <td>What animal does Linda have?</td>\n",
       "      <td>{\"text\": [\"fish\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>Linda has a fish and a truck.</td>\n",
       "      <td>What vehicle does Linda have?</td>\n",
       "      <td>{\"text\": [\"truck\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>Linda has a truck and a fish.</td>\n",
       "      <td>What animal does Linda have?</td>\n",
       "      <td>{\"text\": [\"fish\"], \"answer_start\": [24]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>Linda has a truck and a fish.</td>\n",
       "      <td>What vehicle does Linda have?</td>\n",
       "      <td>{\"text\": [\"truck\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1984 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  context                         question  \\\n",
       "0       Alice has a lizard and a minivan.     What animal does Alice have?   \n",
       "1       Alice has a lizard and a minivan.    What vehicle does Alice have?   \n",
       "2       Alice has a minivan and a lizard.     What animal does Alice have?   \n",
       "3       Alice has a minivan and a lizard.    What vehicle does Alice have?   \n",
       "4          Michelle has a bull and a van.  What animal does Michelle have?   \n",
       "...                                   ...                              ...   \n",
       "1979  Elaine has a tractor and an iguana.   What vehicle does Elaine have?   \n",
       "1980        Linda has a fish and a truck.     What animal does Linda have?   \n",
       "1981        Linda has a fish and a truck.    What vehicle does Linda have?   \n",
       "1982        Linda has a truck and a fish.     What animal does Linda have?   \n",
       "1983        Linda has a truck and a fish.    What vehicle does Linda have?   \n",
       "\n",
       "                                          answers  \n",
       "0      {\"text\": [\"lizard\"], \"answer_start\": [12]}  \n",
       "1     {\"text\": [\"minivan\"], \"answer_start\": [25]}  \n",
       "2      {\"text\": [\"lizard\"], \"answer_start\": [26]}  \n",
       "3     {\"text\": [\"minivan\"], \"answer_start\": [12]}  \n",
       "4        {\"text\": [\"bull\"], \"answer_start\": [15]}  \n",
       "...                                           ...  \n",
       "1979  {\"text\": [\"tractor\"], \"answer_start\": [13]}  \n",
       "1980     {\"text\": [\"fish\"], \"answer_start\": [12]}  \n",
       "1981    {\"text\": [\"truck\"], \"answer_start\": [23]}  \n",
       "1982     {\"text\": [\"fish\"], \"answer_start\": [24]}  \n",
       "1983    {\"text\": [\"truck\"], \"answer_start\": [12]}  \n",
       "\n",
       "[1984 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"animal_vehicle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['dog', 'cat', 'bull', 'cow', 'fish', 'serpent', 'snake', 'lizard', 'hamster', 'rabbit', 'guinea pig', 'iguana', 'duck']\n",
    "vehicles = ['car', 'truck', 'train', 'motorcycle', 'bike', 'firetruck', 'tractor', 'van', 'SUV', 'minivan']\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} bought {a:animal}. {first_name2} bought {a:vehicle}.',\n",
    "            '{first_name2} bought {a:vehicle}. {first_name} bought {a:animal}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who bought an animal?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who bought a vehicle?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    animal=animals,\n",
    "    vehicle=vehicles,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'Animal vs Vehicle v2'\n",
    "# test = MFT(**t, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joan bought a bull. Jonathan bought a train.</td>\n",
       "      <td>Who bought an animal?</td>\n",
       "      <td>{\"text\": [\"Joan\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joan bought a bull. Jonathan bought a train.</td>\n",
       "      <td>Who bought a vehicle?</td>\n",
       "      <td>{\"text\": [\"Jonathan\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jonathan bought a train. Joan bought a bull.</td>\n",
       "      <td>Who bought an animal?</td>\n",
       "      <td>{\"text\": [\"Joan\"], \"answer_start\": [25]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jonathan bought a train. Joan bought a bull.</td>\n",
       "      <td>Who bought a vehicle?</td>\n",
       "      <td>{\"text\": [\"Jonathan\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Katherine bought a snake. Howard bought a train.</td>\n",
       "      <td>Who bought an animal?</td>\n",
       "      <td>{\"text\": [\"Katherine\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>Heather bought a SUV. Ken bought a serpent.</td>\n",
       "      <td>Who bought a vehicle?</td>\n",
       "      <td>{\"text\": [\"Heather\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>Christopher bought a duck. Marilyn bought a tr...</td>\n",
       "      <td>Who bought an animal?</td>\n",
       "      <td>{\"text\": [\"Christopher\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>Christopher bought a duck. Marilyn bought a tr...</td>\n",
       "      <td>Who bought a vehicle?</td>\n",
       "      <td>{\"text\": [\"Marilyn\"], \"answer_start\": [27]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>Marilyn bought a truck. Christopher bought a d...</td>\n",
       "      <td>Who bought an animal?</td>\n",
       "      <td>{\"text\": [\"Christopher\"], \"answer_start\": [24]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>Marilyn bought a truck. Christopher bought a d...</td>\n",
       "      <td>Who bought a vehicle?</td>\n",
       "      <td>{\"text\": [\"Marilyn\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1980 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0          Joan bought a bull. Jonathan bought a train.   \n",
       "1          Joan bought a bull. Jonathan bought a train.   \n",
       "2          Jonathan bought a train. Joan bought a bull.   \n",
       "3          Jonathan bought a train. Joan bought a bull.   \n",
       "4      Katherine bought a snake. Howard bought a train.   \n",
       "...                                                 ...   \n",
       "1975        Heather bought a SUV. Ken bought a serpent.   \n",
       "1976  Christopher bought a duck. Marilyn bought a tr...   \n",
       "1977  Christopher bought a duck. Marilyn bought a tr...   \n",
       "1978  Marilyn bought a truck. Christopher bought a d...   \n",
       "1979  Marilyn bought a truck. Christopher bought a d...   \n",
       "\n",
       "                   question                                          answers  \n",
       "0     Who bought an animal?          {\"text\": [\"Joan\"], \"answer_start\": [0]}  \n",
       "1     Who bought a vehicle?     {\"text\": [\"Jonathan\"], \"answer_start\": [20]}  \n",
       "2     Who bought an animal?         {\"text\": [\"Joan\"], \"answer_start\": [25]}  \n",
       "3     Who bought a vehicle?      {\"text\": [\"Jonathan\"], \"answer_start\": [0]}  \n",
       "4     Who bought an animal?     {\"text\": [\"Katherine\"], \"answer_start\": [0]}  \n",
       "...                     ...                                              ...  \n",
       "1975  Who bought a vehicle?       {\"text\": [\"Heather\"], \"answer_start\": [0]}  \n",
       "1976  Who bought an animal?   {\"text\": [\"Christopher\"], \"answer_start\": [0]}  \n",
       "1977  Who bought a vehicle?      {\"text\": [\"Marilyn\"], \"answer_start\": [27]}  \n",
       "1978  Who bought an animal?  {\"text\": [\"Christopher\"], \"answer_start\": [24]}  \n",
       "1979  Who bought a vehicle?       {\"text\": [\"Marilyn\"], \"answer_start\": [0]}  \n",
       "\n",
       "[1980 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"animal_vehicle2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = [ ('spiritual', 'religious'), ('angry', 'furious'), ('organized', 'organised'),\n",
    "            ('vocal', 'outspoken'), ('grateful', 'thankful'), ('intelligent', 'smart'),\n",
    "            ('humble', 'modest'), ('courageous', 'brave'), ('happy', 'joyful'), ('scared', 'frightened'),\n",
    "           ]\n",
    "\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is very {s1[0]}. {first_name2} is very {s2[0]}.',\n",
    "            '{first_name2} is very {s2[0]}. {first_name} is very {s1[0]}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {s1[1]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {s2[1]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s=synonyms,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    save=True\n",
    "   ))\n",
    "t += crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is very {s1[1]}. {first_name2} is very {s2[1]}.',\n",
    "            '{first_name2} is very {s2[1]}. {first_name} is very {s1[1]}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {s1[0]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {s2[0]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s=synonyms,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    save=True\n",
    "    )) \n",
    "name = 'Synonyms'\n",
    "# test = MFT(**t, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Margaret is very vocal. Ed is very angry.</td>\n",
       "      <td>Who is outspoken?</td>\n",
       "      <td>{\"text\": [\"Margaret\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Margaret is very vocal. Ed is very angry.</td>\n",
       "      <td>Who is furious?</td>\n",
       "      <td>{\"text\": [\"Ed\"], \"answer_start\": [24]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ed is very angry. Margaret is very vocal.</td>\n",
       "      <td>Who is outspoken?</td>\n",
       "      <td>{\"text\": [\"Margaret\"], \"answer_start\": [18]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ed is very angry. Margaret is very vocal.</td>\n",
       "      <td>Who is furious?</td>\n",
       "      <td>{\"text\": [\"Ed\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bruce is very spiritual. Helen is very intelli...</td>\n",
       "      <td>Who is religious?</td>\n",
       "      <td>{\"text\": [\"Bruce\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>Marilyn is very modest. Bill is very joyful.</td>\n",
       "      <td>Who is humble?</td>\n",
       "      <td>{\"text\": [\"Marilyn\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>Amy is very frightened. Emma is very furious.</td>\n",
       "      <td>Who is scared?</td>\n",
       "      <td>{\"text\": [\"Amy\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>Amy is very frightened. Emma is very furious.</td>\n",
       "      <td>Who is angry?</td>\n",
       "      <td>{\"text\": [\"Emma\"], \"answer_start\": [24]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>Emma is very furious. Amy is very frightened.</td>\n",
       "      <td>Who is scared?</td>\n",
       "      <td>{\"text\": [\"Amy\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>Emma is very furious. Amy is very frightened.</td>\n",
       "      <td>Who is angry?</td>\n",
       "      <td>{\"text\": [\"Emma\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1836 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context           question  \\\n",
       "0             Margaret is very vocal. Ed is very angry.  Who is outspoken?   \n",
       "1             Margaret is very vocal. Ed is very angry.    Who is furious?   \n",
       "2             Ed is very angry. Margaret is very vocal.  Who is outspoken?   \n",
       "3             Ed is very angry. Margaret is very vocal.    Who is furious?   \n",
       "4     Bruce is very spiritual. Helen is very intelli...  Who is religious?   \n",
       "...                                                 ...                ...   \n",
       "1831       Marilyn is very modest. Bill is very joyful.     Who is humble?   \n",
       "1832      Amy is very frightened. Emma is very furious.     Who is scared?   \n",
       "1833      Amy is very frightened. Emma is very furious.      Who is angry?   \n",
       "1834      Emma is very furious. Amy is very frightened.     Who is scared?   \n",
       "1835      Emma is very furious. Amy is very frightened.      Who is angry?   \n",
       "\n",
       "                                           answers  \n",
       "0      {\"text\": [\"Margaret\"], \"answer_start\": [0]}  \n",
       "1           {\"text\": [\"Ed\"], \"answer_start\": [24]}  \n",
       "2     {\"text\": [\"Margaret\"], \"answer_start\": [18]}  \n",
       "3            {\"text\": [\"Ed\"], \"answer_start\": [0]}  \n",
       "4         {\"text\": [\"Bruce\"], \"answer_start\": [0]}  \n",
       "...                                            ...  \n",
       "1831    {\"text\": [\"Marilyn\"], \"answer_start\": [0]}  \n",
       "1832        {\"text\": [\"Amy\"], \"answer_start\": [0]}  \n",
       "1833      {\"text\": [\"Emma\"], \"answer_start\": [24]}  \n",
       "1834       {\"text\": [\"Amy\"], \"answer_start\": [22]}  \n",
       "1835       {\"text\": [\"Emma\"], \"answer_start\": [0]}  \n",
       "\n",
       "[1836 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_pairs = [('better', 'worse'), ('older', 'younger'), ('smarter', 'dumber'), ('taller', 'shorter'), ('bigger', 'smaller'), ('stronger', 'weaker'), ('faster', 'slower'), ('darker', 'lighter'), ('richer', 'poorer'), ('happier', 'sadder'), ('louder', 'quieter'), ('warmer', 'colder')]\n",
    "comp_pairs = list(set(comp_pairs))#list(set(comp_pairs + [(x[1], x[0]) for x in comp_pairs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {comp[0]} than {first_name1}.',\n",
    "            '{first_name1} is {comp[1]} than {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {comp[1]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is {comp[0]}?',\n",
    "                '{first_name}',\n",
    "            )\n",
    "            \n",
    "        ]\n",
    "        ,\n",
    "    },\n",
    "    comp=comp_pairs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'A is COMP than B. Who is antonym(COMP)? B'\n",
    "# test = MFT(**t, name=name, description='', capability='Taxonomy')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Roger is smarter than Tom.</td>\n",
       "      <td>Who is dumber?</td>\n",
       "      <td>{\"text\": [\"Tom\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Roger is smarter than Tom.</td>\n",
       "      <td>Who is smarter?</td>\n",
       "      <td>{\"text\": [\"Roger\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom is dumber than Roger.</td>\n",
       "      <td>Who is dumber?</td>\n",
       "      <td>{\"text\": [\"Tom\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tom is dumber than Roger.</td>\n",
       "      <td>Who is smarter?</td>\n",
       "      <td>{\"text\": [\"Roger\"], \"answer_start\": [19]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nicole is smarter than Tom.</td>\n",
       "      <td>Who is dumber?</td>\n",
       "      <td>{\"text\": [\"Tom\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>Ed is poorer than Bob.</td>\n",
       "      <td>Who is richer?</td>\n",
       "      <td>{\"text\": [\"Bob\"], \"answer_start\": [18]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>Sophie is bigger than Scott.</td>\n",
       "      <td>Who is smaller?</td>\n",
       "      <td>{\"text\": [\"Scott\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>Sophie is bigger than Scott.</td>\n",
       "      <td>Who is bigger?</td>\n",
       "      <td>{\"text\": [\"Sophie\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>Scott is smaller than Sophie.</td>\n",
       "      <td>Who is smaller?</td>\n",
       "      <td>{\"text\": [\"Scott\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Scott is smaller than Sophie.</td>\n",
       "      <td>Who is bigger?</td>\n",
       "      <td>{\"text\": [\"Sophie\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1996 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            context         question  \\\n",
       "0        Roger is smarter than Tom.   Who is dumber?   \n",
       "1        Roger is smarter than Tom.  Who is smarter?   \n",
       "2         Tom is dumber than Roger.   Who is dumber?   \n",
       "3         Tom is dumber than Roger.  Who is smarter?   \n",
       "4       Nicole is smarter than Tom.   Who is dumber?   \n",
       "...                             ...              ...   \n",
       "1991         Ed is poorer than Bob.   Who is richer?   \n",
       "1992   Sophie is bigger than Scott.  Who is smaller?   \n",
       "1993   Sophie is bigger than Scott.   Who is bigger?   \n",
       "1994  Scott is smaller than Sophie.  Who is smaller?   \n",
       "1995  Scott is smaller than Sophie.   Who is bigger?   \n",
       "\n",
       "                                         answers  \n",
       "0        {\"text\": [\"Tom\"], \"answer_start\": [22]}  \n",
       "1       {\"text\": [\"Roger\"], \"answer_start\": [0]}  \n",
       "2         {\"text\": [\"Tom\"], \"answer_start\": [0]}  \n",
       "3      {\"text\": [\"Roger\"], \"answer_start\": [19]}  \n",
       "4        {\"text\": [\"Tom\"], \"answer_start\": [23]}  \n",
       "...                                          ...  \n",
       "1991     {\"text\": [\"Bob\"], \"answer_start\": [18]}  \n",
       "1992   {\"text\": [\"Scott\"], \"answer_start\": [22]}  \n",
       "1993   {\"text\": [\"Sophie\"], \"answer_start\": [0]}  \n",
       "1994    {\"text\": [\"Scott\"], \"answer_start\": [0]}  \n",
       "1995  {\"text\": [\"Sophie\"], \"answer_start\": [22]}  \n",
       "\n",
       "[1996 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"compare_antonym\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "antonym_adjs = [('progressive', 'conservative'),('religious', 'secular'),('positive', 'negative'),('defensive', 'offensive'),('rude',  'polite'),('optimistic', 'pessimistic'),('stupid', 'smart'),('negative', 'positive'),('unhappy', 'happy'),('active', 'passive'),('impatient', 'patient'),('powerless', 'powerful'),('visible', 'invisible'),('fat', 'thin'),('bad', 'good'),('cautious', 'brave'), ('hopeful', 'hopeless'),('insecure', 'secure'),('humble', 'proud'),('passive', 'active'),('dependent', 'independent'),('pessimistic', 'optimistic'),('irresponsible', 'responsible'),('courageous', 'fearful')]\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is more {a[0]} than {first_name1}.',\n",
    "            '{first_name1} is more {a[1]} than {first_name}.',\n",
    "            '{first_name} is less {a[1]} than {first_name1}.',\n",
    "            '{first_name1} is less {a[0]} than {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is more {a[0]}?',\n",
    "                '{first_name}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is less {a[0]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is more {a[1]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is less {a[1]}?',\n",
    "                '{first_name}',\n",
    "            ),\n",
    "        ]\n",
    "        ,\n",
    "    },\n",
    "    a = antonym_adjs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'A is more X than B. Who is more antonym(X)? B. Who is less X? B. Who is more X? A. Who is less antonym(X)? A.'\n",
    "# test = MFT(**t, name=name, description='', capability='Taxonomy')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paul is more stupid than Tony.</td>\n",
       "      <td>Who is more stupid?</td>\n",
       "      <td>{\"text\": [\"Paul\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul is more stupid than Tony.</td>\n",
       "      <td>Who is less stupid?</td>\n",
       "      <td>{\"text\": [\"Tony\"], \"answer_start\": [25]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paul is more stupid than Tony.</td>\n",
       "      <td>Who is more smart?</td>\n",
       "      <td>{\"text\": [\"Tony\"], \"answer_start\": [25]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paul is more stupid than Tony.</td>\n",
       "      <td>Who is less smart?</td>\n",
       "      <td>{\"text\": [\"Paul\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tony is more smart than Paul.</td>\n",
       "      <td>Who is more stupid?</td>\n",
       "      <td>{\"text\": [\"Paul\"], \"answer_start\": [24]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>Bill is less powerful than Alison.</td>\n",
       "      <td>Who is less powerful?</td>\n",
       "      <td>{\"text\": [\"Bill\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>Alison is less powerless than Bill.</td>\n",
       "      <td>Who is more powerless?</td>\n",
       "      <td>{\"text\": [\"Bill\"], \"answer_start\": [30]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>Alison is less powerless than Bill.</td>\n",
       "      <td>Who is less powerless?</td>\n",
       "      <td>{\"text\": [\"Alison\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>Alison is less powerless than Bill.</td>\n",
       "      <td>Who is more powerful?</td>\n",
       "      <td>{\"text\": [\"Alison\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>Alison is less powerless than Bill.</td>\n",
       "      <td>Who is less powerful?</td>\n",
       "      <td>{\"text\": [\"Bill\"], \"answer_start\": [30]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  context                question  \\\n",
       "0          Paul is more stupid than Tony.     Who is more stupid?   \n",
       "1          Paul is more stupid than Tony.     Who is less stupid?   \n",
       "2          Paul is more stupid than Tony.      Who is more smart?   \n",
       "3          Paul is more stupid than Tony.      Who is less smart?   \n",
       "4           Tony is more smart than Paul.     Who is more stupid?   \n",
       "...                                   ...                     ...   \n",
       "7995   Bill is less powerful than Alison.   Who is less powerful?   \n",
       "7996  Alison is less powerless than Bill.  Who is more powerless?   \n",
       "7997  Alison is less powerless than Bill.  Who is less powerless?   \n",
       "7998  Alison is less powerless than Bill.   Who is more powerful?   \n",
       "7999  Alison is less powerless than Bill.   Who is less powerful?   \n",
       "\n",
       "                                        answers  \n",
       "0       {\"text\": [\"Paul\"], \"answer_start\": [0]}  \n",
       "1      {\"text\": [\"Tony\"], \"answer_start\": [25]}  \n",
       "2      {\"text\": [\"Tony\"], \"answer_start\": [25]}  \n",
       "3       {\"text\": [\"Paul\"], \"answer_start\": [0]}  \n",
       "4      {\"text\": [\"Paul\"], \"answer_start\": [24]}  \n",
       "...                                         ...  \n",
       "7995    {\"text\": [\"Bill\"], \"answer_start\": [0]}  \n",
       "7996   {\"text\": [\"Bill\"], \"answer_start\": [30]}  \n",
       "7997  {\"text\": [\"Alison\"], \"answer_start\": [0]}  \n",
       "7998  {\"text\": [\"Alison\"], \"answer_start\": [0]}  \n",
       "7999   {\"text\": [\"Bill\"], \"answer_start\": [30]}  \n",
       "\n",
       "[8000 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"compare_moreless_antonym\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original code from https://github.com/marcotcr/checklist/blob/115f123de47ab015b2c3a6baebaffb40bab80c9f/notebooks/SQuAD.ipynb\n",
    "\n",
    "# import pickle\n",
    "# data, answers =  load_squad()\n",
    "# spacy_map =  pickle.load(open('/home/marcotcr/tmp/processed_squad.pkl', 'rb'))\n",
    "# pairs = [(x['passage'], x['question']) for x in data]\n",
    "# processed_pairs = [(spacy_map[x[0]], spacy_map[x[1]]) for x in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(x['context'], x['question']) for x in dataset['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # source: https://github.com/marcotcr/checklist/blob/115f123de47ab015b2c3a6baebaffb40bab80c9f/notebooks/QQP.ipynb\n",
    "# # all_questions = list(all_questions)\n",
    "# # parsed_questions = list(nlp.pipe(all_questions))\n",
    "# # spacy_map = dict([(x, y) for x, y in zip(all_questions, parsed_questions)])\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# all_questions = set() # a set of all questions and context\n",
    "# for x in dataset['train']:\n",
    "#     all_questions.add(x['question'])\n",
    "#     all_questions.add(x['context'])\n",
    "\n",
    "\n",
    "# parsed_questions = list(nlp.pipe(all_questions)) # this takes a while to run \n",
    "# spacy_map = dict([(x, y) for x, y in zip(all_questions, parsed_questions)])\n",
    "\n",
    "import pickle\n",
    "# pickle.dump(spacy_map, open('processed_squad.pkl', 'wb'))\n",
    "# pickle.dump(parsed_questions, open('processed_questions.pkl', 'wb'))\n",
    "spacy_map =  pickle.load(open('processed_squad.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pairs = [(spacy_map[x[0]], spacy_map[x[1]]) for x in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_typo(x):\n",
    "    \"\"\"\n",
    "    x[0]: context\n",
    "    x[1]: question \n",
    "    Perturb.add_typos(x[1]): add a typo to question \n",
    "    \"\"\"\n",
    "    return (x[0], Perturb.add_typos(x[1]))\n",
    "t = Perturb.perturb(pairs, question_typo, nsamples=500)\n",
    "# test = INV(**t, name='Question typo', capability='Robustness', description='')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad)\n",
    "# suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The name iPod was proposed by Vinnie Chieco, a...</td>\n",
       "      <td>Whatf ilm inspired the name of the iPod?</td>\n",
       "      <td>{\"text\": [\"2001: A Space Odyssey\"], \"answer_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Numerous recordings of Chopin's works are avai...</td>\n",
       "      <td>On Chopin's 200tha nniversary critics of what ...</td>\n",
       "      <td>{\"text\": [\"The New York Times\"], \"answer_start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From January 18–20, 2010 a national conference...</td>\n",
       "      <td>What does thep lan call for all rural Tibetan ...</td>\n",
       "      <td>{\"text\": [\"education\"], \"answer_start\": [627]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albert Einstein proposed that the laws of phys...</td>\n",
       "      <td>Before Einstein, speed was though to be relait...</td>\n",
       "      <td>{\"text\": [\"the luminiferous ether\"], \"answer_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Into the first half of the twentieth century a...</td>\n",
       "      <td>hWat is Zhongyang Shangchang?</td>\n",
       "      <td>{\"text\": [\"huge department stores\"], \"answer_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>This creates a linear pitch space in which oct...</td>\n",
       "      <td>The pitch halfway between C (60) and C♯ (61) i...</td>\n",
       "      <td>{\"text\": [\"60.5\"], \"answer_start\": [518]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>The middle up segment is mainly occupied by Me...</td>\n",
       "      <td>When did Seibu, located in Jakarta, er-open?</td>\n",
       "      <td>{\"text\": [\"2007\"], \"answer_start\": [114]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Aposematism, where organisms are brightly colo...</td>\n",
       "      <td>How does aposematism help a specise population?</td>\n",
       "      <td>{\"text\": [\"Upon being harmed (e.g., stung) by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Portuguese cuisine is diverse. The Portuguese ...</td>\n",
       "      <td>What are two popular oNrthern Portugal dishes?</td>\n",
       "      <td>{\"text\": [\"arroz de sarrabulho (rice stewed in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>New York City is home to the headquarters of t...</td>\n",
       "      <td>In what year were theB rooklyn Dodgers founded?</td>\n",
       "      <td>{\"text\": [\"1882\"], \"answer_start\": [473]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    The name iPod was proposed by Vinnie Chieco, a...   \n",
       "1    Numerous recordings of Chopin's works are avai...   \n",
       "2    From January 18–20, 2010 a national conference...   \n",
       "3    Albert Einstein proposed that the laws of phys...   \n",
       "4    Into the first half of the twentieth century a...   \n",
       "..                                                 ...   \n",
       "495  This creates a linear pitch space in which oct...   \n",
       "496  The middle up segment is mainly occupied by Me...   \n",
       "497  Aposematism, where organisms are brightly colo...   \n",
       "498  Portuguese cuisine is diverse. The Portuguese ...   \n",
       "499  New York City is home to the headquarters of t...   \n",
       "\n",
       "                                              question  \\\n",
       "0             Whatf ilm inspired the name of the iPod?   \n",
       "1    On Chopin's 200tha nniversary critics of what ...   \n",
       "2    What does thep lan call for all rural Tibetan ...   \n",
       "3    Before Einstein, speed was though to be relait...   \n",
       "4                        hWat is Zhongyang Shangchang?   \n",
       "..                                                 ...   \n",
       "495  The pitch halfway between C (60) and C♯ (61) i...   \n",
       "496      When did Seibu, located in Jakarta, er-open?    \n",
       "497    How does aposematism help a specise population?   \n",
       "498     What are two popular oNrthern Portugal dishes?   \n",
       "499    In what year were theB rooklyn Dodgers founded?   \n",
       "\n",
       "                                               answers  \n",
       "0    {\"text\": [\"2001: A Space Odyssey\"], \"answer_st...  \n",
       "1    {\"text\": [\"The New York Times\"], \"answer_start...  \n",
       "2       {\"text\": [\"education\"], \"answer_start\": [627]}  \n",
       "3    {\"text\": [\"the luminiferous ether\"], \"answer_s...  \n",
       "4    {\"text\": [\"huge department stores\"], \"answer_s...  \n",
       "..                                                 ...  \n",
       "495          {\"text\": [\"60.5\"], \"answer_start\": [518]}  \n",
       "496          {\"text\": [\"2007\"], \"answer_start\": [114]}  \n",
       "497  {\"text\": [\"Upon being harmed (e.g., stung) by ...  \n",
       "498  {\"text\": [\"arroz de sarrabulho (rice stewed in...  \n",
       "499          {\"text\": [\"1882\"], \"answer_start\": [473]}  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_dataset_fmt(t, 'typo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractions(x):\n",
    "    conts = Perturb.contractions(x[1])\n",
    "    return [(x[0], a) for a in conts]\n",
    "t = Perturb.perturb(pairs, contractions, nsamples=500)\n",
    "# test = INV(**t, name='Question contractions', capability='Robustness', description='')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to a tradition first reported by Sul...</td>\n",
       "      <td>What's the meaning of Thorn Ey?</td>\n",
       "      <td>{\"text\": [\"Thorn Island\"], \"answer_start\": [124]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>By the verse Quran, 2:124, Shias believe that ...</td>\n",
       "      <td>Who knows everything that's needed to get to t...</td>\n",
       "      <td>{\"text\": [\"Imam\"], \"answer_start\": [499]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jehovah's Witnesses is a millenarian restorati...</td>\n",
       "      <td>Who's in charges of directing the Jehovah Witn...</td>\n",
       "      <td>{\"text\": [\"Governing Body of Jehovah's Witness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toxocara canis (dog roundworm) eggs in dog fec...</td>\n",
       "      <td>What's the common name of the species that cau...</td>\n",
       "      <td>{\"text\": [\"dog roundworm\"], \"answer_start\": [16]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After a nonprofit organization has been formed...</td>\n",
       "      <td>What happens if an NPO doesn't abide by the ta...</td>\n",
       "      <td>{\"text\": [\"losing its tax exempt status\"], \"an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>A few lines of the Paris Métro in France opera...</td>\n",
       "      <td>What's required in order for the guide rails t...</td>\n",
       "      <td>{\"text\": [\"a single polarity supply\"], \"answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>The new SuperSpeed bus provides a fourth trans...</td>\n",
       "      <td>What's full-duplex in SuperSpeed transfer mode?</td>\n",
       "      <td>{\"text\": [\"Communication\"], \"answer_start\": [4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>In the US, nutritional standards and recommend...</td>\n",
       "      <td>What's the name of the concept that has replac...</td>\n",
       "      <td>{\"text\": [\"MyPlate\"], \"answer_start\": [248]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Hayek's greatest intellectual debt was to Carl...</td>\n",
       "      <td>Carl Menger's work in social explanation wasn'...</td>\n",
       "      <td>{\"text\": [\"Scottish Enlightenment\"], \"answer_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Richmond is located at the fall line of the Ja...</td>\n",
       "      <td>What're the major roads in Richmond?</td>\n",
       "      <td>{\"text\": [\"Interstate 95 and Interstate 64, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    According to a tradition first reported by Sul...   \n",
       "1    By the verse Quran, 2:124, Shias believe that ...   \n",
       "2    Jehovah's Witnesses is a millenarian restorati...   \n",
       "3    Toxocara canis (dog roundworm) eggs in dog fec...   \n",
       "4    After a nonprofit organization has been formed...   \n",
       "..                                                 ...   \n",
       "495  A few lines of the Paris Métro in France opera...   \n",
       "496  The new SuperSpeed bus provides a fourth trans...   \n",
       "497  In the US, nutritional standards and recommend...   \n",
       "498  Hayek's greatest intellectual debt was to Carl...   \n",
       "499  Richmond is located at the fall line of the Ja...   \n",
       "\n",
       "                                              question  \\\n",
       "0                      What's the meaning of Thorn Ey?   \n",
       "1    Who knows everything that's needed to get to t...   \n",
       "2    Who's in charges of directing the Jehovah Witn...   \n",
       "3    What's the common name of the species that cau...   \n",
       "4    What happens if an NPO doesn't abide by the ta...   \n",
       "..                                                 ...   \n",
       "495  What's required in order for the guide rails t...   \n",
       "496    What's full-duplex in SuperSpeed transfer mode?   \n",
       "497  What's the name of the concept that has replac...   \n",
       "498  Carl Menger's work in social explanation wasn'...   \n",
       "499               What're the major roads in Richmond?   \n",
       "\n",
       "                                               answers  \n",
       "0    {\"text\": [\"Thorn Island\"], \"answer_start\": [124]}  \n",
       "1            {\"text\": [\"Imam\"], \"answer_start\": [499]}  \n",
       "2    {\"text\": [\"Governing Body of Jehovah's Witness...  \n",
       "3    {\"text\": [\"dog roundworm\"], \"answer_start\": [16]}  \n",
       "4    {\"text\": [\"losing its tax exempt status\"], \"an...  \n",
       "..                                                 ...  \n",
       "495  {\"text\": [\"a single polarity supply\"], \"answer...  \n",
       "496  {\"text\": [\"Communication\"], \"answer_start\": [4...  \n",
       "497       {\"text\": [\"MyPlate\"], \"answer_start\": [248]}  \n",
       "498  {\"text\": [\"Scottish Enlightenment\"], \"answer_s...  \n",
       "499  {\"text\": [\"Interstate 95 and Interstate 64, an...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_dataset_fmt(t, 'contractions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add random sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = set()\n",
    "for x, _ in processed_pairs:\n",
    "    for y in x.sents:\n",
    "        random_sentences.add(y.text)\n",
    "random_sentences = list(random_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecturally, the school has a Catholic character.\n",
      "Atop the Main Building's gold dome is a golden statue of the Virgin Mary.\n",
      "Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\".\n",
      "Next to the Main Building is the Basilica of the Sacred Heart.\n",
      "Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection.\n",
      "It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858.\n",
      "At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "for y in spacy_map[pairs[0][0]].sents:\n",
    "    print(y.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91957"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_random_sentence(x, **kwargs):\n",
    "    random_s = np.random.choice(random_sentences)\n",
    "    while random_s in x[0]:\n",
    "        random_s = np.random.choice(random_sentences)\n",
    "    random_s = random_s.strip('.') + '. '\n",
    "    meta = ['add to end: %s' % random_s, 'add to beg: %s' % random_s]\n",
    "    return [(x[0] + random_s, x[1]), (random_s + x[0], x[1])], meta\n",
    "\n",
    "def format_add(x, pred, conf, label=None, meta=None):\n",
    "    ret = format_squad(x, pred, conf, label, meta)\n",
    "    if meta:\n",
    "        ret += 'Perturb: %s\\n' % meta\n",
    "    return ret\n",
    "\n",
    "t = Perturb.perturb(pairs, add_random_sentence, nsamples=500, meta=True)\n",
    "# test = INV(**t, name='Add random sentence to context', capability='Robustness', description='')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_add)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>During the American Civil War, American cotton...</td>\n",
       "      <td>What did the abandonment of Egyptian cotton me...</td>\n",
       "      <td>{\"text\": [\"bankruptcy\"], \"answer_start\": [761]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The sovereign territory of Israel (according t...</td>\n",
       "      <td>What's home to 57% of the nation's population?</td>\n",
       "      <td>{\"text\": [\"Israeli Coastal Plain\"], \"answer_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The two became friends, and for many years liv...</td>\n",
       "      <td>What was the charity that Liszt and Chopin las...</td>\n",
       "      <td>{\"text\": [\"the Beethoven Memorial in Bonn\"], \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Each season premieres with the audition round,...</td>\n",
       "      <td>In the audition rounds, what do contestants wh...</td>\n",
       "      <td>{\"text\": [\"a golden ticket\"], \"answer_start\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The value of the U.S. dollar declined signific...</td>\n",
       "      <td>What was the Federal Reserve designed to furnish?</td>\n",
       "      <td>{\"text\": [\"an \\\"elastic\\\" currency\"], \"answer_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Between 1949 and the 1980s, telephone communic...</td>\n",
       "      <td>What company has a 40% stake in OTE?</td>\n",
       "      <td>{\"text\": [\"Deutsche Telekom\"], \"answer_start\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Including Kerry, the Democratic primary race h...</td>\n",
       "      <td>What was DiFruscia's position?</td>\n",
       "      <td>{\"text\": [\"State Representative\"], \"answer_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Basic sanitation techniques can have a profoun...</td>\n",
       "      <td>What is a solution to help this problem?</td>\n",
       "      <td>{\"text\": [\"implementation of educational progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Polarization is predictable from an antenna's ...</td>\n",
       "      <td>What is a more complicated type of polarizatio...</td>\n",
       "      <td>{\"text\": [\"quad antenna\"], \"answer_start\": [121]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>The first institute of madrasa education was a...</td>\n",
       "      <td>Who was the teacher at the first madrasa?</td>\n",
       "      <td>{\"text\": [\"Hazrat Muhammad\"], \"answer_start\": ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    During the American Civil War, American cotton...   \n",
       "1    The sovereign territory of Israel (according t...   \n",
       "2    The two became friends, and for many years liv...   \n",
       "3    Each season premieres with the audition round,...   \n",
       "4    The value of the U.S. dollar declined signific...   \n",
       "..                                                 ...   \n",
       "495  Between 1949 and the 1980s, telephone communic...   \n",
       "496  Including Kerry, the Democratic primary race h...   \n",
       "497  Basic sanitation techniques can have a profoun...   \n",
       "498  Polarization is predictable from an antenna's ...   \n",
       "499  The first institute of madrasa education was a...   \n",
       "\n",
       "                                              question  \\\n",
       "0    What did the abandonment of Egyptian cotton me...   \n",
       "1       What's home to 57% of the nation's population?   \n",
       "2    What was the charity that Liszt and Chopin las...   \n",
       "3    In the audition rounds, what do contestants wh...   \n",
       "4    What was the Federal Reserve designed to furnish?   \n",
       "..                                                 ...   \n",
       "495               What company has a 40% stake in OTE?   \n",
       "496                     What was DiFruscia's position?   \n",
       "497           What is a solution to help this problem?   \n",
       "498  What is a more complicated type of polarizatio...   \n",
       "499          Who was the teacher at the first madrasa?   \n",
       "\n",
       "                                               answers  \n",
       "0      {\"text\": [\"bankruptcy\"], \"answer_start\": [761]}  \n",
       "1    {\"text\": [\"Israeli Coastal Plain\"], \"answer_st...  \n",
       "2    {\"text\": [\"the Beethoven Memorial in Bonn\"], \"...  \n",
       "3    {\"text\": [\"a golden ticket\"], \"answer_start\": ...  \n",
       "4    {\"text\": [\"an \\\"elastic\\\" currency\"], \"answer_...  \n",
       "..                                                 ...  \n",
       "495  {\"text\": [\"Deutsche Telekom\"], \"answer_start\":...  \n",
       "496  {\"text\": [\"State Representative\"], \"answer_sta...  \n",
       "497  {\"text\": [\"implementation of educational progr...  \n",
       "498  {\"text\": [\"quad antenna\"], \"answer_start\": [121]}  \n",
       "499  {\"text\": [\"Hazrat Muhammad\"], \"answer_start\": ...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_dataset_fmt(t, 'random_sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def change_thing(change_fn):\n",
    "    def change_both(cq, **kwargs):\n",
    "        context, question = cq\n",
    "        a = change_fn(context, meta=True)\n",
    "        if not a:\n",
    "            return None\n",
    "        changed, meta = a\n",
    "        ret = []\n",
    "        for c, m in zip(changed, meta):\n",
    "            new_q = re.sub(r'\\b%s\\b' % re.escape(m[0]), m[1], question.text)\n",
    "            ret.append((c, new_q))\n",
    "        return ret, meta\n",
    "    return change_both\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expect_same(orig_pred, pred, orig_conf, conf, labels=None, meta=None):\n",
    "    if not meta:\n",
    "        return pred == orig_pred\n",
    "    return pred == re.sub(r'\\b%s\\b' % re.escape(meta[0]), meta[1], orig_pred)\n",
    "\n",
    "def format_replace(x, pred, conf, label=None, meta=None):\n",
    "    ret = format_squad(x, pred, conf, label, meta)\n",
    "    if meta:\n",
    "        ret += 'Perturb: %s -> %s\\n' % meta\n",
    "    return ret\n",
    "\n",
    "def format_replace_context(x, pred, conf, label=None, meta=None):\n",
    "    ret = format_squad_with_context(x, pred, conf, label, meta)\n",
    "    if meta:\n",
    "        ret += 'Perturb: %s -> %s\\n' % meta\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(processed_pairs, change_thing(Perturb.change_names), nsamples=500, meta=True)\n",
    "\n",
    "# test = INV(**t, name='Change name everywhere', capability='NER',\n",
    "#           description='', expect=Expect.pairwise(expect_same))\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(3, format_example_fn=format_replace)\n",
    "# suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Battle of Osan, the first significant Amer...</td>\n",
       "      <td>At what Battle did the 24th Infantry Division ...</td>\n",
       "      <td>{\"text\": [\"Battle of Taejon\"], \"answer_start\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It seems to have been St Bernard of Clairvaux ...</td>\n",
       "      <td>What did the query starter believe to be the u...</td>\n",
       "      <td>{\"text\": [\"How can there be absence of sin whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>During the presidential referendum in Egypt, K...</td>\n",
       "      <td>What was Qutb's sentence?</td>\n",
       "      <td>{\"text\": [\"executed\"], \"answer_start\": [505]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Many of the city's buildings are in the Georgi...</td>\n",
       "      <td>What has the old Psychiatric Hospital been tur...</td>\n",
       "      <td>{\"text\": [\"Atkins Hall\"], \"answer_start\": [478]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Following the start of the Arab Spring in 2011...</td>\n",
       "      <td>About what percentage of the Libyan population...</td>\n",
       "      <td>{\"text\": [\"30\"], \"answer_start\": [810]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>This eventually led to LBJ's Civil Rights Act,...</td>\n",
       "      <td>Outside of the private business regulations, w...</td>\n",
       "      <td>{\"text\": [\"integrate public facilities\"], \"ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>In addition, the city has about 160 museums—th...</td>\n",
       "      <td>Where is the house that Leon Trotsky was murde...</td>\n",
       "      <td>{\"text\": [\"Coyoac\\u00e1n\"], \"answer_start\": [6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>In 1975, a group of Chicago Cubs fans based in...</td>\n",
       "      <td>Who currently heads the Emil Verban Society?</td>\n",
       "      <td>{\"text\": [\"Illinois Senator Dick Durbin\"], \"an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Captain John Charles Jackson and Thomas Gilber...</td>\n",
       "      <td>At what island did the Globe arrive in 1824?</td>\n",
       "      <td>{\"text\": [\"Mulgrave\"], \"answer_start\": [557]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Michael Howard also stepped down as commission...</td>\n",
       "      <td>Who became commissioner of the AFL after Micha...</td>\n",
       "      <td>{\"text\": [\"Scott Butera\"], \"answer_start\": [128]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    The Battle of Osan, the first significant Amer...   \n",
       "1    It seems to have been St Bernard of Clairvaux ...   \n",
       "2    During the presidential referendum in Egypt, K...   \n",
       "3    Many of the city's buildings are in the Georgi...   \n",
       "4    Following the start of the Arab Spring in 2011...   \n",
       "..                                                 ...   \n",
       "495  This eventually led to LBJ's Civil Rights Act,...   \n",
       "496  In addition, the city has about 160 museums—th...   \n",
       "497  In 1975, a group of Chicago Cubs fans based in...   \n",
       "498  Captain John Charles Jackson and Thomas Gilber...   \n",
       "499  Michael Howard also stepped down as commission...   \n",
       "\n",
       "                                              question  \\\n",
       "0    At what Battle did the 24th Infantry Division ...   \n",
       "1    What did the query starter believe to be the u...   \n",
       "2                            What was Qutb's sentence?   \n",
       "3    What has the old Psychiatric Hospital been tur...   \n",
       "4    About what percentage of the Libyan population...   \n",
       "..                                                 ...   \n",
       "495  Outside of the private business regulations, w...   \n",
       "496  Where is the house that Leon Trotsky was murde...   \n",
       "497       Who currently heads the Emil Verban Society?   \n",
       "498       At what island did the Globe arrive in 1824?   \n",
       "499  Who became commissioner of the AFL after Micha...   \n",
       "\n",
       "                                               answers  \n",
       "0    {\"text\": [\"Battle of Taejon\"], \"answer_start\":...  \n",
       "1    {\"text\": [\"How can there be absence of sin whe...  \n",
       "2        {\"text\": [\"executed\"], \"answer_start\": [505]}  \n",
       "3     {\"text\": [\"Atkins Hall\"], \"answer_start\": [478]}  \n",
       "4              {\"text\": [\"30\"], \"answer_start\": [810]}  \n",
       "..                                                 ...  \n",
       "495  {\"text\": [\"integrate public facilities\"], \"ans...  \n",
       "496  {\"text\": [\"Coyoac\\u00e1n\"], \"answer_start\": [6...  \n",
       "497  {\"text\": [\"Illinois Senator Dick Durbin\"], \"an...  \n",
       "498      {\"text\": [\"Mulgrave\"], \"answer_start\": [557]}  \n",
       "499  {\"text\": [\"Scott Butera\"], \"answer_start\": [128]}  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_dataset_fmt(t, 'name_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(processed_pairs, change_thing(Perturb.change_location), nsamples=500, meta=True)\n",
    "\n",
    "# test = INV(**t, name='Change location everywhere', capability='NER',\n",
    "#           description='', expect=Expect.pairwise(expect_same))\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(3, format_example_fn=format_replace)\n",
    "# suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A second Irvine gastronomical claim to fame is...</td>\n",
       "      <td>Who is the founder of Louis' Lunch in Irvine?</td>\n",
       "      <td>{\"text\": [\"Louis Lassen\"], \"answer_start\": [216]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In July 2013, there were 41,000 non-Germans by...</td>\n",
       "      <td>Which towns have the highest immigrant populat...</td>\n",
       "      <td>{\"text\": [\"Erfurt, Jena, Weimar and Ilmenau\"],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indonesia was the last Western republic to gra...</td>\n",
       "      <td>Who was the first woman to serve on the Federa...</td>\n",
       "      <td>{\"text\": [\"Elisabeth Kopp\"], \"answer_start\": [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Starting in the 1890s and stretching in some p...</td>\n",
       "      <td>In what year was Alaska's capital officially c...</td>\n",
       "      <td>{\"text\": [\"1906\"], \"answer_start\": [295]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John, the youngest of five sons of King Henry ...</td>\n",
       "      <td>When did Richard I become king?</td>\n",
       "      <td>{\"text\": [\"1189\"], \"answer_start\": [457]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>The changes brought about by these development...</td>\n",
       "      <td>Historians from what country in particular do ...</td>\n",
       "      <td>{\"text\": [\"Italy\"], \"answer_start\": [446]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Throughout their history, Slavs came into cont...</td>\n",
       "      <td>Who vanished from the population of the Balkans?</td>\n",
       "      <td>{\"text\": [\"The Thracians and Illyrians\"], \"ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Along with the desire for independence, tensio...</td>\n",
       "      <td>What position did Muslims have in the Indian p...</td>\n",
       "      <td>{\"text\": [\"minority\"], \"answer_start\": [147]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>From childhood, Gaddafi was aware of the invol...</td>\n",
       "      <td>What country occupied Libya during World War II?</td>\n",
       "      <td>{\"text\": [\"his nation was occupied by Italy\"],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>In 1821, after Myanmar's War of Independence f...</td>\n",
       "      <td>Was Texas a part of Myanmar?</td>\n",
       "      <td>{\"text\": [\"In 1821, after Mexico's War of Inde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    A second Irvine gastronomical claim to fame is...   \n",
       "1    In July 2013, there were 41,000 non-Germans by...   \n",
       "2    Indonesia was the last Western republic to gra...   \n",
       "3    Starting in the 1890s and stretching in some p...   \n",
       "4    John, the youngest of five sons of King Henry ...   \n",
       "..                                                 ...   \n",
       "495  The changes brought about by these development...   \n",
       "496  Throughout their history, Slavs came into cont...   \n",
       "497  Along with the desire for independence, tensio...   \n",
       "498  From childhood, Gaddafi was aware of the invol...   \n",
       "499  In 1821, after Myanmar's War of Independence f...   \n",
       "\n",
       "                                              question  \\\n",
       "0        Who is the founder of Louis' Lunch in Irvine?   \n",
       "1    Which towns have the highest immigrant populat...   \n",
       "2    Who was the first woman to serve on the Federa...   \n",
       "3    In what year was Alaska's capital officially c...   \n",
       "4                      When did Richard I become king?   \n",
       "..                                                 ...   \n",
       "495  Historians from what country in particular do ...   \n",
       "496   Who vanished from the population of the Balkans?   \n",
       "497  What position did Muslims have in the Indian p...   \n",
       "498   What country occupied Libya during World War II?   \n",
       "499                       Was Texas a part of Myanmar?   \n",
       "\n",
       "                                               answers  \n",
       "0    {\"text\": [\"Louis Lassen\"], \"answer_start\": [216]}  \n",
       "1    {\"text\": [\"Erfurt, Jena, Weimar and Ilmenau\"],...  \n",
       "2    {\"text\": [\"Elisabeth Kopp\"], \"answer_start\": [...  \n",
       "3            {\"text\": [\"1906\"], \"answer_start\": [295]}  \n",
       "4            {\"text\": [\"1189\"], \"answer_start\": [457]}  \n",
       "..                                                 ...  \n",
       "495         {\"text\": [\"Italy\"], \"answer_start\": [446]}  \n",
       "496  {\"text\": [\"The Thracians and Illyrians\"], \"ans...  \n",
       "497      {\"text\": [\"minority\"], \"answer_start\": [147]}  \n",
       "498  {\"text\": [\"his nation was occupied by Italy\"],...  \n",
       "499  {\"text\": [\"In 1821, after Mexico's War of Inde...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_dataset_fmt(t, 'location_change')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'Both {first_name} and {first_name2} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "            'Both {first_name2} and {first_name} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'There was a change in profession'\n",
    "# test = MFT(**t, expect=expect_squad, capability='Temporal', name=name, description='' )\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Both Bill and Amy were investors, but there wa...</td>\n",
       "      <td>Who is an actress?</td>\n",
       "      <td>{\"text\": [\"Bill\"], \"answer_start\": [5]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Both Amy and Bill were investors, but there wa...</td>\n",
       "      <td>Who is an actress?</td>\n",
       "      <td>{\"text\": [\"Bill\"], \"answer_start\": [13]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Both Larry and Jay were editors, but there was...</td>\n",
       "      <td>Who is a photographer?</td>\n",
       "      <td>{\"text\": [\"Larry\"], \"answer_start\": [5]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Both Jay and Larry were editors, but there was...</td>\n",
       "      <td>Who is a photographer?</td>\n",
       "      <td>{\"text\": [\"Larry\"], \"answer_start\": [13]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Both Alice and Larry were waitresss, but there...</td>\n",
       "      <td>Who is a photographer?</td>\n",
       "      <td>{\"text\": [\"Alice\"], \"answer_start\": [5]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>Both Rose and Judy were investors, but there w...</td>\n",
       "      <td>Who is a musician?</td>\n",
       "      <td>{\"text\": [\"Judy\"], \"answer_start\": [14]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>Both Rose and Greg were artists, but there was...</td>\n",
       "      <td>Who is a DJ?</td>\n",
       "      <td>{\"text\": [\"Rose\"], \"answer_start\": [5]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>Both Greg and Rose were artists, but there was...</td>\n",
       "      <td>Who is a DJ?</td>\n",
       "      <td>{\"text\": [\"Rose\"], \"answer_start\": [14]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Both Colin and Dick were executives, but there...</td>\n",
       "      <td>Who is an editor?</td>\n",
       "      <td>{\"text\": [\"Colin\"], \"answer_start\": [5]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Both Dick and Colin were executives, but there...</td>\n",
       "      <td>Who is an editor?</td>\n",
       "      <td>{\"text\": [\"Colin\"], \"answer_start\": [14]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>972 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    Both Bill and Amy were investors, but there wa...   \n",
       "1    Both Amy and Bill were investors, but there wa...   \n",
       "2    Both Larry and Jay were editors, but there was...   \n",
       "3    Both Jay and Larry were editors, but there was...   \n",
       "4    Both Alice and Larry were waitresss, but there...   \n",
       "..                                                 ...   \n",
       "967  Both Rose and Judy were investors, but there w...   \n",
       "968  Both Rose and Greg were artists, but there was...   \n",
       "969  Both Greg and Rose were artists, but there was...   \n",
       "970  Both Colin and Dick were executives, but there...   \n",
       "971  Both Dick and Colin were executives, but there...   \n",
       "\n",
       "                   question                                    answers  \n",
       "0        Who is an actress?    {\"text\": [\"Bill\"], \"answer_start\": [5]}  \n",
       "1        Who is an actress?   {\"text\": [\"Bill\"], \"answer_start\": [13]}  \n",
       "2    Who is a photographer?   {\"text\": [\"Larry\"], \"answer_start\": [5]}  \n",
       "3    Who is a photographer?  {\"text\": [\"Larry\"], \"answer_start\": [13]}  \n",
       "4    Who is a photographer?   {\"text\": [\"Alice\"], \"answer_start\": [5]}  \n",
       "..                      ...                                        ...  \n",
       "967      Who is a musician?   {\"text\": [\"Judy\"], \"answer_start\": [14]}  \n",
       "968            Who is a DJ?    {\"text\": [\"Rose\"], \"answer_start\": [5]}  \n",
       "969            Who is a DJ?   {\"text\": [\"Rose\"], \"answer_start\": [14]}  \n",
       "970       Who is an editor?   {\"text\": [\"Colin\"], \"answer_start\": [5]}  \n",
       "971       Who is an editor?  {\"text\": [\"Colin\"], \"answer_start\": [14]}  \n",
       "\n",
       "[972 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"temproal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} became a {prof} before {first_name2} did.',\n",
    "            '{first_name2} became a {prof} after {first_name} did.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who became a {prof} first?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who became a {prof} last?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Understanding before / after -> first / last.'\n",
    "# test = MFT(**t, expect=expect_squad, capability='Temporal', name=name, description='' )\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virginia became a reporter before Roy did.</td>\n",
       "      <td>Who became a reporter first?</td>\n",
       "      <td>{\"text\": [\"Virginia\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virginia became a reporter before Roy did.</td>\n",
       "      <td>Who became a reporter last?</td>\n",
       "      <td>{\"text\": [\"Roy\"], \"answer_start\": [34]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roy became a reporter after Virginia did.</td>\n",
       "      <td>Who became a reporter first?</td>\n",
       "      <td>{\"text\": [\"Virginia\"], \"answer_start\": [28]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roy became a reporter after Virginia did.</td>\n",
       "      <td>Who became a reporter last?</td>\n",
       "      <td>{\"text\": [\"Roy\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald became a nurse before Scott did.</td>\n",
       "      <td>Who became a nurse first?</td>\n",
       "      <td>{\"text\": [\"Donald\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>Stephen became a interpreter after Henry did.</td>\n",
       "      <td>Who became a interpreter last?</td>\n",
       "      <td>{\"text\": [\"Stephen\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>Katherine became a entrepreneur before Jessica...</td>\n",
       "      <td>Who became a entrepreneur first?</td>\n",
       "      <td>{\"text\": [\"Katherine\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>Katherine became a entrepreneur before Jessica...</td>\n",
       "      <td>Who became a entrepreneur last?</td>\n",
       "      <td>{\"text\": [\"Jessica\"], \"answer_start\": [39]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>Jessica became a entrepreneur after Katherine ...</td>\n",
       "      <td>Who became a entrepreneur first?</td>\n",
       "      <td>{\"text\": [\"Katherine\"], \"answer_start\": [36]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>Jessica became a entrepreneur after Katherine ...</td>\n",
       "      <td>Who became a entrepreneur last?</td>\n",
       "      <td>{\"text\": [\"Jessica\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1988 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0            Virginia became a reporter before Roy did.   \n",
       "1            Virginia became a reporter before Roy did.   \n",
       "2             Roy became a reporter after Virginia did.   \n",
       "3             Roy became a reporter after Virginia did.   \n",
       "4               Donald became a nurse before Scott did.   \n",
       "...                                                 ...   \n",
       "1983      Stephen became a interpreter after Henry did.   \n",
       "1984  Katherine became a entrepreneur before Jessica...   \n",
       "1985  Katherine became a entrepreneur before Jessica...   \n",
       "1986  Jessica became a entrepreneur after Katherine ...   \n",
       "1987  Jessica became a entrepreneur after Katherine ...   \n",
       "\n",
       "                              question  \\\n",
       "0         Who became a reporter first?   \n",
       "1          Who became a reporter last?   \n",
       "2         Who became a reporter first?   \n",
       "3          Who became a reporter last?   \n",
       "4            Who became a nurse first?   \n",
       "...                                ...   \n",
       "1983    Who became a interpreter last?   \n",
       "1984  Who became a entrepreneur first?   \n",
       "1985   Who became a entrepreneur last?   \n",
       "1986  Who became a entrepreneur first?   \n",
       "1987   Who became a entrepreneur last?   \n",
       "\n",
       "                                            answers  \n",
       "0       {\"text\": [\"Virginia\"], \"answer_start\": [0]}  \n",
       "1           {\"text\": [\"Roy\"], \"answer_start\": [34]}  \n",
       "2      {\"text\": [\"Virginia\"], \"answer_start\": [28]}  \n",
       "3            {\"text\": [\"Roy\"], \"answer_start\": [0]}  \n",
       "4         {\"text\": [\"Donald\"], \"answer_start\": [0]}  \n",
       "...                                             ...  \n",
       "1983     {\"text\": [\"Stephen\"], \"answer_start\": [0]}  \n",
       "1984   {\"text\": [\"Katherine\"], \"answer_start\": [0]}  \n",
       "1985    {\"text\": [\"Jessica\"], \"answer_start\": [39]}  \n",
       "1986  {\"text\": [\"Katherine\"], \"answer_start\": [36]}  \n",
       "1987     {\"text\": [\"Jessica\"], \"answer_start\": [0]}  \n",
       "\n",
       "[1988 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"before_after\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is not {a:prof}. {first_name2} is.',\n",
    "            '{first_name2} is {a:prof}. {first_name} is not.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Negation in context, may or may not be in question'\n",
    "# test = MFT(**t, expect=expect_squad, capability='Negation', name=name, description='' )\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gary is not a reporter. Evelyn is.</td>\n",
       "      <td>Who is a reporter?</td>\n",
       "      <td>{\"text\": [\"Evelyn\"], \"answer_start\": [24]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gary is not a reporter. Evelyn is.</td>\n",
       "      <td>Who is not a reporter?</td>\n",
       "      <td>{\"text\": [\"Gary\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evelyn is a reporter. Gary is not.</td>\n",
       "      <td>Who is a reporter?</td>\n",
       "      <td>{\"text\": [\"Evelyn\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evelyn is a reporter. Gary is not.</td>\n",
       "      <td>Who is not a reporter?</td>\n",
       "      <td>{\"text\": [\"Gary\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don is not an actor. Benjamin is.</td>\n",
       "      <td>Who is an actor?</td>\n",
       "      <td>{\"text\": [\"Benjamin\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>Philip is a photographer. Alan is not.</td>\n",
       "      <td>Who is not a photographer?</td>\n",
       "      <td>{\"text\": [\"Alan\"], \"answer_start\": [26]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>Catherine is not a DJ. James is.</td>\n",
       "      <td>Who is a DJ?</td>\n",
       "      <td>{\"text\": [\"James\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>Catherine is not a DJ. James is.</td>\n",
       "      <td>Who is not a DJ?</td>\n",
       "      <td>{\"text\": [\"Catherine\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>James is a DJ. Catherine is not.</td>\n",
       "      <td>Who is a DJ?</td>\n",
       "      <td>{\"text\": [\"James\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>James is a DJ. Catherine is not.</td>\n",
       "      <td>Who is not a DJ?</td>\n",
       "      <td>{\"text\": [\"Catherine\"], \"answer_start\": [15]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1988 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     context                    question  \\\n",
       "0         Gary is not a reporter. Evelyn is.          Who is a reporter?   \n",
       "1         Gary is not a reporter. Evelyn is.      Who is not a reporter?   \n",
       "2         Evelyn is a reporter. Gary is not.          Who is a reporter?   \n",
       "3         Evelyn is a reporter. Gary is not.      Who is not a reporter?   \n",
       "4          Don is not an actor. Benjamin is.            Who is an actor?   \n",
       "...                                      ...                         ...   \n",
       "1983  Philip is a photographer. Alan is not.  Who is not a photographer?   \n",
       "1984        Catherine is not a DJ. James is.                Who is a DJ?   \n",
       "1985        Catherine is not a DJ. James is.            Who is not a DJ?   \n",
       "1986        James is a DJ. Catherine is not.                Who is a DJ?   \n",
       "1987        James is a DJ. Catherine is not.            Who is not a DJ?   \n",
       "\n",
       "                                            answers  \n",
       "0        {\"text\": [\"Evelyn\"], \"answer_start\": [24]}  \n",
       "1           {\"text\": [\"Gary\"], \"answer_start\": [0]}  \n",
       "2         {\"text\": [\"Evelyn\"], \"answer_start\": [0]}  \n",
       "3          {\"text\": [\"Gary\"], \"answer_start\": [22]}  \n",
       "4      {\"text\": [\"Benjamin\"], \"answer_start\": [21]}  \n",
       "...                                             ...  \n",
       "1983       {\"text\": [\"Alan\"], \"answer_start\": [26]}  \n",
       "1984      {\"text\": [\"James\"], \"answer_start\": [23]}  \n",
       "1985   {\"text\": [\"Catherine\"], \"answer_start\": [0]}  \n",
       "1986       {\"text\": [\"James\"], \"answer_start\": [0]}  \n",
       "1987  {\"text\": [\"Catherine\"], \"answer_start\": [15]}  \n",
       "\n",
       "[1988 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"negation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not in context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:prof}. {first_name2} is {a:prof2}.',\n",
    "            '{first_name2} is {a:prof2}. {first_name} is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Negation in question only.'\n",
    "# test = MFT(**t, expect=expect_squad, capability='Negation', name=name, description='' )\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virginia is an author. Lawrence is a photograp...</td>\n",
       "      <td>Who is an author?</td>\n",
       "      <td>{\"text\": [\"Virginia\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virginia is an author. Lawrence is a photograp...</td>\n",
       "      <td>Who is not an author?</td>\n",
       "      <td>{\"text\": [\"Lawrence\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virginia is an author. Lawrence is a photograp...</td>\n",
       "      <td>Who is a photographer?</td>\n",
       "      <td>{\"text\": [\"Lawrence\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virginia is an author. Lawrence is a photograp...</td>\n",
       "      <td>Who is not a photographer?</td>\n",
       "      <td>{\"text\": [\"Virginia\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lawrence is a photographer. Virginia is an aut...</td>\n",
       "      <td>Who is an author?</td>\n",
       "      <td>{\"text\": [\"Virginia\"], \"answer_start\": [28]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>Ruth is an interpreter. Joan is a waitress.</td>\n",
       "      <td>Who is not a waitress?</td>\n",
       "      <td>{\"text\": [\"Ruth\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>Joan is a waitress. Ruth is an interpreter.</td>\n",
       "      <td>Who is an interpreter?</td>\n",
       "      <td>{\"text\": [\"Ruth\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>Joan is a waitress. Ruth is an interpreter.</td>\n",
       "      <td>Who is not an interpreter?</td>\n",
       "      <td>{\"text\": [\"Joan\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>Joan is a waitress. Ruth is an interpreter.</td>\n",
       "      <td>Who is a waitress?</td>\n",
       "      <td>{\"text\": [\"Joan\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>Joan is a waitress. Ruth is an interpreter.</td>\n",
       "      <td>Who is not a waitress?</td>\n",
       "      <td>{\"text\": [\"Ruth\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3816 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0     Virginia is an author. Lawrence is a photograp...   \n",
       "1     Virginia is an author. Lawrence is a photograp...   \n",
       "2     Virginia is an author. Lawrence is a photograp...   \n",
       "3     Virginia is an author. Lawrence is a photograp...   \n",
       "4     Lawrence is a photographer. Virginia is an aut...   \n",
       "...                                                 ...   \n",
       "3811        Ruth is an interpreter. Joan is a waitress.   \n",
       "3812        Joan is a waitress. Ruth is an interpreter.   \n",
       "3813        Joan is a waitress. Ruth is an interpreter.   \n",
       "3814        Joan is a waitress. Ruth is an interpreter.   \n",
       "3815        Joan is a waitress. Ruth is an interpreter.   \n",
       "\n",
       "                        question                                       answers  \n",
       "0              Who is an author?   {\"text\": [\"Virginia\"], \"answer_start\": [0]}  \n",
       "1          Who is not an author?  {\"text\": [\"Lawrence\"], \"answer_start\": [23]}  \n",
       "2         Who is a photographer?  {\"text\": [\"Lawrence\"], \"answer_start\": [23]}  \n",
       "3     Who is not a photographer?   {\"text\": [\"Virginia\"], \"answer_start\": [0]}  \n",
       "4              Who is an author?  {\"text\": [\"Virginia\"], \"answer_start\": [28]}  \n",
       "...                          ...                                           ...  \n",
       "3811      Who is not a waitress?       {\"text\": [\"Ruth\"], \"answer_start\": [0]}  \n",
       "3812      Who is an interpreter?      {\"text\": [\"Ruth\"], \"answer_start\": [20]}  \n",
       "3813  Who is not an interpreter?       {\"text\": [\"Joan\"], \"answer_start\": [0]}  \n",
       "3814          Who is a waitress?       {\"text\": [\"Joan\"], \"answer_start\": [0]}  \n",
       "3815      Who is not a waitress?      {\"text\": [\"Ruth\"], \"answer_start\": [20]}  \n",
       "\n",
       "[3816 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"negation_question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness spinoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "fewer_profs = ['doctor', 'nurse', 'secretary', 'CEO']\n",
    "t = editor.template(\n",
    "    [\n",
    "        ('{male} is not {a:prof}, {female} is.', 'Who is {a:prof}?', '{female}', 'woman', '{prof}'),\n",
    "        ('{female} is not {a:prof}, {male} is.', 'Who is {a:prof}?', '{male}', 'man', '{prof}'),\n",
    "    ],\n",
    "#     prof=professions + ['doctor'],\n",
    "    prof=fewer_profs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=1000,\n",
    "    unroll=True,\n",
    "    save=True,\n",
    "    )\n",
    "data = [(d[0], d[1]) for d in t.data]\n",
    "labels = [d[2] for d in t.data]\n",
    "meta = [(d[3], d[4]) for d in t.data]\n",
    "\n",
    "# test = MFT(data, expect=expect_squad, labels=labels, meta=meta, templates=t.templates,\n",
    "#           name='M/F failure rates should be similar for different professions', capability='Fairness',\n",
    "#           description='Using negation in context.')\n",
    "# test.run(predconfs, n=100)\n",
    "\n",
    "# def print_fair(test):\n",
    "#     c = collections.Counter(test.meta)\n",
    "#     fail = collections.Counter([tuple(x) for x in np.array(test.meta)[test.fail_idxs()]])\n",
    "#     profs = set()\n",
    "#     for sex, prof in fail:\n",
    "#         profs.add(prof)\n",
    "#     prof_fail = {}\n",
    "#     get_fail = lambda f:fail[f] / c[f]\n",
    "#     for prof in profs:\n",
    "#         fail_m = get_fail(('man', prof))\n",
    "#         fail_f = get_fail(('woman', prof))\n",
    "#         prof_fail[prof] = (fail_m, fail_f)\n",
    "#     print('%-13s fail_men fail_women (count)' % 'profession')\n",
    "#     for prof, vs in sorted(prof_fail.items(), key=lambda x:max(x[1][0], x[1][1]), reverse=True):\n",
    "#         fail_m, fail_f = vs\n",
    "#         print('%-13s   %.1f      %.1f     (%d)' % (prof, 100 * fail_m, 100 * fail_f, c[('man', prof)]))\n",
    "# print_fair(test)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.data = [[i] for i in data]\n",
    "t.labels = [[i] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jay is not a CEO, Anne is.</td>\n",
       "      <td>Who is a CEO?</td>\n",
       "      <td>{\"text\": [\"Anne\"], \"answer_start\": [18]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anne is not a CEO, Jay is.</td>\n",
       "      <td>Who is a CEO?</td>\n",
       "      <td>{\"text\": [\"Jay\"], \"answer_start\": [19]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Johnny is not a nurse, Heather is.</td>\n",
       "      <td>Who is a nurse?</td>\n",
       "      <td>{\"text\": [\"Heather\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heather is not a nurse, Johnny is.</td>\n",
       "      <td>Who is a nurse?</td>\n",
       "      <td>{\"text\": [\"Johnny\"], \"answer_start\": [24]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Henry is not a nurse, Ann is.</td>\n",
       "      <td>Who is a nurse?</td>\n",
       "      <td>{\"text\": [\"Ann\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>Barbara is not a doctor, Peter is.</td>\n",
       "      <td>Who is a doctor?</td>\n",
       "      <td>{\"text\": [\"Peter\"], \"answer_start\": [25]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>Tim is not a CEO, Rose is.</td>\n",
       "      <td>Who is a CEO?</td>\n",
       "      <td>{\"text\": [\"Rose\"], \"answer_start\": [18]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>Rose is not a CEO, Tim is.</td>\n",
       "      <td>Who is a CEO?</td>\n",
       "      <td>{\"text\": [\"Tim\"], \"answer_start\": [19]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>Brian is not a doctor, Harriet is.</td>\n",
       "      <td>Who is a doctor?</td>\n",
       "      <td>{\"text\": [\"Harriet\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>Harriet is not a doctor, Brian is.</td>\n",
       "      <td>Who is a doctor?</td>\n",
       "      <td>{\"text\": [\"Brian\"], \"answer_start\": [25]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 context          question  \\\n",
       "0             Jay is not a CEO, Anne is.     Who is a CEO?   \n",
       "1             Anne is not a CEO, Jay is.     Who is a CEO?   \n",
       "2     Johnny is not a nurse, Heather is.   Who is a nurse?   \n",
       "3     Heather is not a nurse, Johnny is.   Who is a nurse?   \n",
       "4          Henry is not a nurse, Ann is.   Who is a nurse?   \n",
       "...                                  ...               ...   \n",
       "1977  Barbara is not a doctor, Peter is.  Who is a doctor?   \n",
       "1978          Tim is not a CEO, Rose is.     Who is a CEO?   \n",
       "1979          Rose is not a CEO, Tim is.     Who is a CEO?   \n",
       "1980  Brian is not a doctor, Harriet is.  Who is a doctor?   \n",
       "1981  Harriet is not a doctor, Brian is.  Who is a doctor?   \n",
       "\n",
       "                                          answers  \n",
       "0        {\"text\": [\"Anne\"], \"answer_start\": [18]}  \n",
       "1         {\"text\": [\"Jay\"], \"answer_start\": [19]}  \n",
       "2     {\"text\": [\"Heather\"], \"answer_start\": [23]}  \n",
       "3      {\"text\": [\"Johnny\"], \"answer_start\": [24]}  \n",
       "4         {\"text\": [\"Ann\"], \"answer_start\": [22]}  \n",
       "...                                           ...  \n",
       "1977    {\"text\": [\"Peter\"], \"answer_start\": [25]}  \n",
       "1978     {\"text\": [\"Rose\"], \"answer_start\": [18]}  \n",
       "1979      {\"text\": [\"Tim\"], \"answer_start\": [19]}  \n",
       "1980  {\"text\": [\"Harriet\"], \"answer_start\": [23]}  \n",
       "1981    {\"text\": [\"Brian\"], \"answer_start\": [25]}  \n",
       "\n",
       "[1982 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"fair\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'actress' in professions:\n",
    "    professions.remove('actress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{female} and {male} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{male} and {female} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "            '{female} and {male} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{male}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{female}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Basic coref, he / she'\n",
    "# test = MFT(**t, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jeff and Dorothy are friends. He is an actor, ...</td>\n",
       "      <td>Who is an actor?</td>\n",
       "      <td>{\"text\": [\"Jeff\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeff and Dorothy are friends. He is an actor, ...</td>\n",
       "      <td>Who is an interpreter?</td>\n",
       "      <td>{\"text\": [\"Dorothy\"], \"answer_start\": [9]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dorothy and Jeff are friends. He is an actor, ...</td>\n",
       "      <td>Who is an actor?</td>\n",
       "      <td>{\"text\": [\"Jeff\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dorothy and Jeff are friends. He is an actor, ...</td>\n",
       "      <td>Who is an interpreter?</td>\n",
       "      <td>{\"text\": [\"Dorothy\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeff and Dorothy are friends. She is an interp...</td>\n",
       "      <td>Who is an actor?</td>\n",
       "      <td>{\"text\": [\"Jeff\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>Katie and Brian are friends. He is a waitress,...</td>\n",
       "      <td>Who is an executive?</td>\n",
       "      <td>{\"text\": [\"Katie\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>Brian and Katie are friends. She is an executi...</td>\n",
       "      <td>Who is a waitress?</td>\n",
       "      <td>{\"text\": [\"Brian\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>Brian and Katie are friends. She is an executi...</td>\n",
       "      <td>Who is an executive?</td>\n",
       "      <td>{\"text\": [\"Katie\"], \"answer_start\": [10]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902</th>\n",
       "      <td>Katie and Brian are friends. She is an executi...</td>\n",
       "      <td>Who is a waitress?</td>\n",
       "      <td>{\"text\": [\"Brian\"], \"answer_start\": [10]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3903</th>\n",
       "      <td>Katie and Brian are friends. She is an executi...</td>\n",
       "      <td>Who is an executive?</td>\n",
       "      <td>{\"text\": [\"Katie\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3904 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0     Jeff and Dorothy are friends. He is an actor, ...   \n",
       "1     Jeff and Dorothy are friends. He is an actor, ...   \n",
       "2     Dorothy and Jeff are friends. He is an actor, ...   \n",
       "3     Dorothy and Jeff are friends. He is an actor, ...   \n",
       "4     Jeff and Dorothy are friends. She is an interp...   \n",
       "...                                                 ...   \n",
       "3899  Katie and Brian are friends. He is a waitress,...   \n",
       "3900  Brian and Katie are friends. She is an executi...   \n",
       "3901  Brian and Katie are friends. She is an executi...   \n",
       "3902  Katie and Brian are friends. She is an executi...   \n",
       "3903  Katie and Brian are friends. She is an executi...   \n",
       "\n",
       "                    question                                     answers  \n",
       "0           Who is an actor?     {\"text\": [\"Jeff\"], \"answer_start\": [0]}  \n",
       "1     Who is an interpreter?  {\"text\": [\"Dorothy\"], \"answer_start\": [9]}  \n",
       "2           Who is an actor?    {\"text\": [\"Jeff\"], \"answer_start\": [12]}  \n",
       "3     Who is an interpreter?  {\"text\": [\"Dorothy\"], \"answer_start\": [0]}  \n",
       "4           Who is an actor?     {\"text\": [\"Jeff\"], \"answer_start\": [0]}  \n",
       "...                      ...                                         ...  \n",
       "3899    Who is an executive?    {\"text\": [\"Katie\"], \"answer_start\": [0]}  \n",
       "3900      Who is a waitress?    {\"text\": [\"Brian\"], \"answer_start\": [0]}  \n",
       "3901    Who is an executive?   {\"text\": [\"Katie\"], \"answer_start\": [10]}  \n",
       "3902      Who is a waitress?   {\"text\": [\"Brian\"], \"answer_start\": [10]}  \n",
       "3903    Who is an executive?    {\"text\": [\"Katie\"], \"answer_start\": [0]}  \n",
       "\n",
       "[3904 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"basic_coref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. His mom is {a:prof}.',\n",
    "            '{female} and {male} are friends. His mom is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Whose mom is {a:prof}?',\n",
    "                '{male}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    ))\n",
    "t += crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. Her mom is {a:prof}.',\n",
    "            '{female} and {male} are friends. Her mom is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Whose mom is {a:prof}?',\n",
    "                '{female}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    ))\n",
    "\n",
    "name = 'Basic coref, his / her'\n",
    "# test = MFT(**t, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sam and Alison are friends. His mom is an actor.</td>\n",
       "      <td>Whose mom is an actor?</td>\n",
       "      <td>{\"text\": [\"Sam\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alison and Sam are friends. His mom is an actor.</td>\n",
       "      <td>Whose mom is an actor?</td>\n",
       "      <td>{\"text\": [\"Sam\"], \"answer_start\": [11]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jay and Sara are friends. His mom is a writer.</td>\n",
       "      <td>Whose mom is a writer?</td>\n",
       "      <td>{\"text\": [\"Jay\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sara and Jay are friends. His mom is a writer.</td>\n",
       "      <td>Whose mom is a writer?</td>\n",
       "      <td>{\"text\": [\"Jay\"], \"answer_start\": [9]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edward and Anna are friends. His mom is an arc...</td>\n",
       "      <td>Whose mom is an architect?</td>\n",
       "      <td>{\"text\": [\"Edward\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Sally and Andrew are friends. Her mom is an in...</td>\n",
       "      <td>Whose mom is an interpreter?</td>\n",
       "      <td>{\"text\": [\"Sally\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Johnny and Lauren are friends. Her mom is a pr...</td>\n",
       "      <td>Whose mom is a producer?</td>\n",
       "      <td>{\"text\": [\"Lauren\"], \"answer_start\": [11]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Lauren and Johnny are friends. Her mom is a pr...</td>\n",
       "      <td>Whose mom is a producer?</td>\n",
       "      <td>{\"text\": [\"Lauren\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Stephen and Wendy are friends. Her mom is an a...</td>\n",
       "      <td>Whose mom is an attorney?</td>\n",
       "      <td>{\"text\": [\"Wendy\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Wendy and Stephen are friends. Her mom is an a...</td>\n",
       "      <td>Whose mom is an attorney?</td>\n",
       "      <td>{\"text\": [\"Wendy\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0     Sam and Alison are friends. His mom is an actor.   \n",
       "1     Alison and Sam are friends. His mom is an actor.   \n",
       "2       Jay and Sara are friends. His mom is a writer.   \n",
       "3       Sara and Jay are friends. His mom is a writer.   \n",
       "4    Edward and Anna are friends. His mom is an arc...   \n",
       "..                                                 ...   \n",
       "993  Sally and Andrew are friends. Her mom is an in...   \n",
       "994  Johnny and Lauren are friends. Her mom is a pr...   \n",
       "995  Lauren and Johnny are friends. Her mom is a pr...   \n",
       "996  Stephen and Wendy are friends. Her mom is an a...   \n",
       "997  Wendy and Stephen are friends. Her mom is an a...   \n",
       "\n",
       "                         question                                     answers  \n",
       "0          Whose mom is an actor?      {\"text\": [\"Sam\"], \"answer_start\": [0]}  \n",
       "1          Whose mom is an actor?     {\"text\": [\"Sam\"], \"answer_start\": [11]}  \n",
       "2          Whose mom is a writer?      {\"text\": [\"Jay\"], \"answer_start\": [0]}  \n",
       "3          Whose mom is a writer?      {\"text\": [\"Jay\"], \"answer_start\": [9]}  \n",
       "4      Whose mom is an architect?   {\"text\": [\"Edward\"], \"answer_start\": [0]}  \n",
       "..                            ...                                         ...  \n",
       "993  Whose mom is an interpreter?    {\"text\": [\"Sally\"], \"answer_start\": [0]}  \n",
       "994      Whose mom is a producer?  {\"text\": [\"Lauren\"], \"answer_start\": [11]}  \n",
       "995      Whose mom is a producer?   {\"text\": [\"Lauren\"], \"answer_start\": [0]}  \n",
       "996     Whose mom is an attorney?   {\"text\": [\"Wendy\"], \"answer_start\": [12]}  \n",
       "997     Whose mom is an attorney?    {\"text\": [\"Wendy\"], \"answer_start\": [0]}  \n",
       "\n",
       "[998 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"basic_coref2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Former, latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1}.',\n",
    "            '{first_name2} and {first_name} are friends. The latter is {a:prof1}.',\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1} and the latter is {a:prof2}.',\n",
    "            '{first_name2} and {first_name} are friends. The former is {a:prof2} and the latter is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'Former / Latter'\n",
    "# test = MFT(**t, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kathy and Harriet are friends. The former is a...</td>\n",
       "      <td>Who is an artist?</td>\n",
       "      <td>{\"text\": [\"Kathy\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harriet and Kathy are friends. The latter is a...</td>\n",
       "      <td>Who is an artist?</td>\n",
       "      <td>{\"text\": [\"Kathy\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kathy and Harriet are friends. The former is a...</td>\n",
       "      <td>Who is an artist?</td>\n",
       "      <td>{\"text\": [\"Kathy\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harriet and Kathy are friends. The former is a...</td>\n",
       "      <td>Who is an artist?</td>\n",
       "      <td>{\"text\": [\"Kathy\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fred and Tim are friends. The former is an actor.</td>\n",
       "      <td>Who is an actor?</td>\n",
       "      <td>{\"text\": [\"Fred\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>Leslie and Jay are friends. The former is an o...</td>\n",
       "      <td>Who is an escort?</td>\n",
       "      <td>{\"text\": [\"Jay\"], \"answer_start\": [11]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>Deborah and Alice are friends. The former is a...</td>\n",
       "      <td>Who is an organizer?</td>\n",
       "      <td>{\"text\": [\"Deborah\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>Alice and Deborah are friends. The latter is a...</td>\n",
       "      <td>Who is an organizer?</td>\n",
       "      <td>{\"text\": [\"Deborah\"], \"answer_start\": [10]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>Deborah and Alice are friends. The former is a...</td>\n",
       "      <td>Who is an organizer?</td>\n",
       "      <td>{\"text\": [\"Deborah\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>Alice and Deborah are friends. The former is a...</td>\n",
       "      <td>Who is an organizer?</td>\n",
       "      <td>{\"text\": [\"Deborah\"], \"answer_start\": [10]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context              question  \\\n",
       "0     Kathy and Harriet are friends. The former is a...     Who is an artist?   \n",
       "1     Harriet and Kathy are friends. The latter is a...     Who is an artist?   \n",
       "2     Kathy and Harriet are friends. The former is a...     Who is an artist?   \n",
       "3     Harriet and Kathy are friends. The former is a...     Who is an artist?   \n",
       "4     Fred and Tim are friends. The former is an actor.      Who is an actor?   \n",
       "...                                                 ...                   ...   \n",
       "1915  Leslie and Jay are friends. The former is an o...     Who is an escort?   \n",
       "1916  Deborah and Alice are friends. The former is a...  Who is an organizer?   \n",
       "1917  Alice and Deborah are friends. The latter is a...  Who is an organizer?   \n",
       "1918  Deborah and Alice are friends. The former is a...  Who is an organizer?   \n",
       "1919  Alice and Deborah are friends. The former is a...  Who is an organizer?   \n",
       "\n",
       "                                          answers  \n",
       "0        {\"text\": [\"Kathy\"], \"answer_start\": [0]}  \n",
       "1       {\"text\": [\"Kathy\"], \"answer_start\": [12]}  \n",
       "2        {\"text\": [\"Kathy\"], \"answer_start\": [0]}  \n",
       "3       {\"text\": [\"Kathy\"], \"answer_start\": [12]}  \n",
       "4         {\"text\": [\"Fred\"], \"answer_start\": [0]}  \n",
       "...                                           ...  \n",
       "1915      {\"text\": [\"Jay\"], \"answer_start\": [11]}  \n",
       "1916   {\"text\": [\"Deborah\"], \"answer_start\": [0]}  \n",
       "1917  {\"text\": [\"Deborah\"], \"answer_start\": [10]}  \n",
       "1918   {\"text\": [\"Deborah\"], \"answer_start\": [0]}  \n",
       "1919  {\"text\": [\"Deborah\"], \"answer_start\": [10]}  \n",
       "\n",
       "[1920 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"former\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pattern\n",
    "import pattern.en\n",
    "pverb = ['love', 'hate', 'like', 'remember', 'recognize', 'trust', 'deserve', 'understand', 'blame', 'dislike', 'prefer', 'follow', 'notice', 'hurt', 'bother', 'support', 'believe', 'accept', 'attack']\n",
    "a = pattern.en.tenses('loves')[0]\n",
    "b = pattern.en.tenses('stolen')[0]\n",
    "pverb = [(pattern.en.conjugate(v, *a), pattern.en.conjugate(v, *b)) for v in pverb]\n",
    "\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} {v[0]} {first_name2}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who {v[0]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    v=pverb,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Agent / object distinction'\n",
    "# test = MFT(**t, expect=expect_squad, name=name, description='', capability='SRL')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Martin dislikes Jean.</td>\n",
       "      <td>Who dislikes?</td>\n",
       "      <td>{\"text\": [\"Martin\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Martin dislikes Jean.</td>\n",
       "      <td>Who is disliked?</td>\n",
       "      <td>{\"text\": [\"Jean\"], \"answer_start\": [16]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jean is disliked by Martin.</td>\n",
       "      <td>Who dislikes?</td>\n",
       "      <td>{\"text\": [\"Martin\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jean is disliked by Martin.</td>\n",
       "      <td>Who is disliked?</td>\n",
       "      <td>{\"text\": [\"Jean\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Katherine trusts Frances.</td>\n",
       "      <td>Who trusts?</td>\n",
       "      <td>{\"text\": [\"Katherine\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>Suzanne is believed by Kate.</td>\n",
       "      <td>Who is believed?</td>\n",
       "      <td>{\"text\": [\"Suzanne\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>Dan attacks Greg.</td>\n",
       "      <td>Who attacks?</td>\n",
       "      <td>{\"text\": [\"Dan\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>Dan attacks Greg.</td>\n",
       "      <td>Who is attacked?</td>\n",
       "      <td>{\"text\": [\"Greg\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>Greg is attacked by Dan.</td>\n",
       "      <td>Who attacks?</td>\n",
       "      <td>{\"text\": [\"Dan\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Greg is attacked by Dan.</td>\n",
       "      <td>Who is attacked?</td>\n",
       "      <td>{\"text\": [\"Greg\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1996 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           context          question  \\\n",
       "0            Martin dislikes Jean.     Who dislikes?   \n",
       "1            Martin dislikes Jean.  Who is disliked?   \n",
       "2      Jean is disliked by Martin.     Who dislikes?   \n",
       "3      Jean is disliked by Martin.  Who is disliked?   \n",
       "4        Katherine trusts Frances.       Who trusts?   \n",
       "...                            ...               ...   \n",
       "1991  Suzanne is believed by Kate.  Who is believed?   \n",
       "1992             Dan attacks Greg.      Who attacks?   \n",
       "1993             Dan attacks Greg.  Who is attacked?   \n",
       "1994      Greg is attacked by Dan.      Who attacks?   \n",
       "1995      Greg is attacked by Dan.  Who is attacked?   \n",
       "\n",
       "                                           answers  \n",
       "0        {\"text\": [\"Martin\"], \"answer_start\": [0]}  \n",
       "1         {\"text\": [\"Jean\"], \"answer_start\": [16]}  \n",
       "2       {\"text\": [\"Martin\"], \"answer_start\": [20]}  \n",
       "3          {\"text\": [\"Jean\"], \"answer_start\": [0]}  \n",
       "4     {\"text\": [\"Katherine\"], \"answer_start\": [0]}  \n",
       "...                                            ...  \n",
       "1991    {\"text\": [\"Suzanne\"], \"answer_start\": [0]}  \n",
       "1992        {\"text\": [\"Dan\"], \"answer_start\": [0]}  \n",
       "1993      {\"text\": [\"Greg\"], \"answer_start\": [12]}  \n",
       "1994       {\"text\": [\"Dan\"], \"answer_start\": [20]}  \n",
       "1995       {\"text\": [\"Greg\"], \"answer_start\": [0]}  \n",
       "\n",
       "[1996 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} {v[0]} {first_name2}. {first_name2} {v[0]} {first_name3}.',\n",
    "            '{first_name} {v[0]} {first_name2}. {first_name3} is {v[1]} by {first_name2}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}. {first_name2} {v[0]} {first_name3}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}. {first_name3} is {v[1]} by {first_name2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who {v[0]} {first_name2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who {v[0]} {first_name3}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]} by {first_name}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]} by {first_name2}?',\n",
    "                '{first_name3}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    v=pverb,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Agent / object distinction with 3 agents'\n",
    "# test = MFT(**t, expect=expect_squad, name=name, description='', capability='SRL')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Victoria notices Fiona. Fiona notices Laura.</td>\n",
       "      <td>Who notices Fiona?</td>\n",
       "      <td>{\"text\": [\"Victoria\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Victoria notices Fiona. Fiona notices Laura.</td>\n",
       "      <td>Who notices Laura?</td>\n",
       "      <td>{\"text\": [\"Fiona\"], \"answer_start\": [17]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Victoria notices Fiona. Fiona notices Laura.</td>\n",
       "      <td>Who is noticed by Victoria?</td>\n",
       "      <td>{\"text\": [\"Fiona\"], \"answer_start\": [17]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Victoria notices Fiona. Fiona notices Laura.</td>\n",
       "      <td>Who is noticed by Fiona?</td>\n",
       "      <td>{\"text\": [\"Laura\"], \"answer_start\": [38]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Victoria notices Fiona. Laura is noticed by Fi...</td>\n",
       "      <td>Who notices Fiona?</td>\n",
       "      <td>{\"text\": [\"Victoria\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7899</th>\n",
       "      <td>Nick is disliked by Catherine. Nick dislikes S...</td>\n",
       "      <td>Who is disliked by Nick?</td>\n",
       "      <td>{\"text\": [\"Sara\"], \"answer_start\": [45]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7900</th>\n",
       "      <td>Nick is disliked by Catherine. Sara is dislike...</td>\n",
       "      <td>Who dislikes Nick?</td>\n",
       "      <td>{\"text\": [\"Catherine\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7901</th>\n",
       "      <td>Nick is disliked by Catherine. Sara is dislike...</td>\n",
       "      <td>Who dislikes Sara?</td>\n",
       "      <td>{\"text\": [\"Nick\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7902</th>\n",
       "      <td>Nick is disliked by Catherine. Sara is dislike...</td>\n",
       "      <td>Who is disliked by Catherine?</td>\n",
       "      <td>{\"text\": [\"Nick\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7903</th>\n",
       "      <td>Nick is disliked by Catherine. Sara is dislike...</td>\n",
       "      <td>Who is disliked by Nick?</td>\n",
       "      <td>{\"text\": [\"Sara\"], \"answer_start\": [31]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7904 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0          Victoria notices Fiona. Fiona notices Laura.   \n",
       "1          Victoria notices Fiona. Fiona notices Laura.   \n",
       "2          Victoria notices Fiona. Fiona notices Laura.   \n",
       "3          Victoria notices Fiona. Fiona notices Laura.   \n",
       "4     Victoria notices Fiona. Laura is noticed by Fi...   \n",
       "...                                                 ...   \n",
       "7899  Nick is disliked by Catherine. Nick dislikes S...   \n",
       "7900  Nick is disliked by Catherine. Sara is dislike...   \n",
       "7901  Nick is disliked by Catherine. Sara is dislike...   \n",
       "7902  Nick is disliked by Catherine. Sara is dislike...   \n",
       "7903  Nick is disliked by Catherine. Sara is dislike...   \n",
       "\n",
       "                           question  \\\n",
       "0                Who notices Fiona?   \n",
       "1                Who notices Laura?   \n",
       "2       Who is noticed by Victoria?   \n",
       "3          Who is noticed by Fiona?   \n",
       "4                Who notices Fiona?   \n",
       "...                             ...   \n",
       "7899       Who is disliked by Nick?   \n",
       "7900             Who dislikes Nick?   \n",
       "7901             Who dislikes Sara?   \n",
       "7902  Who is disliked by Catherine?   \n",
       "7903       Who is disliked by Nick?   \n",
       "\n",
       "                                            answers  \n",
       "0       {\"text\": [\"Victoria\"], \"answer_start\": [0]}  \n",
       "1         {\"text\": [\"Fiona\"], \"answer_start\": [17]}  \n",
       "2         {\"text\": [\"Fiona\"], \"answer_start\": [17]}  \n",
       "3         {\"text\": [\"Laura\"], \"answer_start\": [38]}  \n",
       "4       {\"text\": [\"Victoria\"], \"answer_start\": [0]}  \n",
       "...                                             ...  \n",
       "7899       {\"text\": [\"Sara\"], \"answer_start\": [45]}  \n",
       "7900  {\"text\": [\"Catherine\"], \"answer_start\": [20]}  \n",
       "7901        {\"text\": [\"Nick\"], \"answer_start\": [0]}  \n",
       "7902        {\"text\": [\"Nick\"], \"answer_start\": [0]}  \n",
       "7903       {\"text\": [\"Sara\"], \"answer_start\": [31]}  \n",
       "\n",
       "[7904 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"agent2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = 'new_data' \n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59350"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_csv('checklist_train.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([\n",
    "    df_train[['context','question','answers']],\n",
    "    frame]\n",
    ").iloc[np.random.permutation(len(combined))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv('combined_train.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1d3a3554611ef5f9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/syang/.cache/huggingface/datasets/csv/default-1d3a3554611ef5f9/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/syang/.cache/huggingface/datasets/csv/default-1d3a3554611ef5f9/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c684336eece4d8c846a5dd1ba179638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/146949 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('csv', data_files='combined_train.csv')\n",
    "def format_dataset(example):\n",
    "    \"\"\"\n",
    "    string to dictionary \n",
    "    dictionary became string when saved to csv. need to convert it back to dict.  \n",
    "    \"\"\"\n",
    "    example['answers'] = json.loads(example['answers']) \n",
    "    return example\n",
    "dataset = dataset.map(format_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
